<div class="Box-sc-g0xbh4-0 QkQOb js-snippet-clipboard-copy-unpositioned" data-hpc="true"><article class="markdown-body entry-content container-lg" itemprop="text"><p align="center" dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/wandb/wandb/blob/main/assets/logo-dark.svg#gh-dark-mode-only" _msthidden="1"><img src="https://github.com/wandb/wandb/raw/main/assets/logo-dark.svg#gh-dark-mode-only" width="600" alt="Weights &amp; Biases" style="max-width: 100%;" _msthidden="A" _mstalt="352612" _msthash="325"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/wandb/wandb/blob/main/assets/logo-light.svg#gh-light-mode-only"><img src="https://github.com/wandb/wandb/raw/main/assets/logo-light.svg#gh-light-mode-only" width="600" alt="æƒé‡å’Œåå·®" style="max-width: 100%;" _mstalt="352612" _msthash="326"></a>
</p>
<p align="center" dir="auto">
<a href="https://pypi.python.org/pypi/wandb" rel="nofollow"><img src="https://camo.githubusercontent.com/dd40995ddde5aa05b24ba55c3b232cbd09f2e0baca6bb824903059189a9d6f05/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f77616e6462" data-canonical-src="https://img.shields.io/pypi/v/wandb" style="max-width: 100%;"></a>
<a href="https://anaconda.org/conda-forge/wandb" rel="nofollow"><img src="https://camo.githubusercontent.com/d6debbd567284c2299c655117d81fd58eb3c082ad7285c20b7ad98c86331a8bb/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f77616e6462" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/wandb" style="max-width: 100%;"></a>
<a href="https://pypi.python.org/pypi/wandb" rel="nofollow"><img src="https://camo.githubusercontent.com/648a89bbc5bf63a375b7ed6b0700a01d9e636491c3bc25591f516384fd7be91d/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f77616e6462" data-canonical-src="https://img.shields.io/pypi/pyversions/wandb" style="max-width: 100%;"></a>
<a href="https://circleci.com/gh/wandb/wandb" rel="nofollow"><img src="https://camo.githubusercontent.com/3e96d8ddcfdd1010c035c6eabce4c9e30afbce8749a71e370ac005ea247c1e50/68747470733a2f2f696d672e736869656c64732e696f2f636972636c6563692f6275696c642f6769746875622f77616e64622f77616e64622f6d61696e" data-canonical-src="https://img.shields.io/circleci/build/github/wandb/wandb/main" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/wandb/wandb" rel="nofollow"><img src="https://camo.githubusercontent.com/328774a44fcf3abcf8e10a6f471bfbc24cf95d23933c9150a73366ce4e243627/68747470733a2f2f696d672e736869656c64732e696f2f636f6465636f762f632f67682f77616e64622f77616e6462" data-canonical-src="https://img.shields.io/codecov/c/gh/wandb/wandb" style="max-width: 100%;"></a>
</p>
<p align="center" dir="auto">
<a href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_%26_Biases.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width: 100%;"></a>
</p>
<p dir="auto" _msttexthash="915794451" _msthash="327">ä½¿ç”¨W&amp;Bæ›´å¿«åœ°æ„å»ºæ›´å¥½çš„æ¨¡å‹ã€‚è·Ÿè¸ªå’Œå¯è§†åŒ–æœºå™¨å­¦ä¹ ç®¡é“çš„æ‰€æœ‰éƒ¨åˆ†ï¼Œä»æ•°æ®é›†åˆ°ç”Ÿäº§æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚ä»Šå¤©å°±å¼€å§‹ä½¿ç”¨W&amp;Bå§ï¼Œ<a href="https://wandb.com?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow" _istranslated="1">æ³¨å†Œä¸€ä¸ªW&amp;Bè´¦æˆ·å§ï¼</a></p>
<br>
<p dir="auto" _msttexthash="393671499" _msthash="328">æ„å»º LLM åº”ç”¨ç¨‹åºï¼Ÿä½¿ç”¨æˆ‘ä»¬é¢å‘ GenAI çš„æ–°å·¥å…·å¥—ä»¶ <a href="https://wandb.github.io/weave?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow" _istranslated="1">Weave</a> è·Ÿè¸ªã€è°ƒè¯•ã€è¯„ä¼°å’Œç›‘æ§ LLM åº”ç”¨ç¨‹åºã€‚</p>
<p dir="auto">&nbsp;</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="5144373" _msthash="329">æ–‡æ¡£</h1><a id="user-content-documentation" class="anchor" aria-label="æ°¸ä¹…é“¾æ¥ï¼š æ–‡æ¡£" href="#documentation" _mstaria-label="559767" _msthash="330"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p align="center" dir="auto">
<a href="https://docs.wandb.ai/guides/track?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow">
<themed-picture data-catalyst-inline="true" data-catalyst=""><picture>
  <source media="(prefers-color-scheme: dark)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_dark_background/experiments-dark.svg" width="12.5%">
  <source media="(prefers-color-scheme: light)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_light/experiments-light.svg" width="12.5%">
  <img alt="æƒé‡å’Œåå·®å®éªŒ" src="/wandb/wandb/raw/main" style="visibility:visible;max-width:100%;" _mstalt="739128" _msthash="331">
</picture></themed-picture>
</a>
<a href="https://docs.wandb.ai/guides/reports?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow">
<themed-picture data-catalyst-inline="true" data-catalyst=""><picture>
  <source media="(prefers-color-scheme: dark)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_dark_background/reports-dark.svg" width="12.5%">
  <source media="(prefers-color-scheme: light)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_light/reports-light.svg" width="12.5%">
  <img alt="æƒé‡å’Œåå·®æŠ¥å‘Š" src="/wandb/wandb/raw/main" style="visibility:visible;max-width:100%;" _mstalt="565422" _msthash="332">
</picture></themed-picture>
</a>
<a href="https://docs.wandb.ai/guides/artifacts?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow">
<themed-picture data-catalyst-inline="true" data-catalyst=""><picture>
  <source media="(prefers-color-scheme: dark)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_dark_background/artifacts-dark.svg" width="12.5%">
  <source media="(prefers-color-scheme: light)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_light/artifacts-light.svg" width="12.5%">
  <img alt="Weights and Biases ä¼ªå½±" src="/wandb/wandb/raw/main" style="visibility:visible;max-width:100%;" _mstalt="638092" _msthash="333">
</picture></themed-picture>
</a>
<a href="https://docs.wandb.ai/guides/tables?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow">
<themed-picture data-catalyst-inline="true" data-catalyst=""><picture>
  <source media="(prefers-color-scheme: dark)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_dark_background/tables-dark.svg" width="12.5%">
  <source media="(prefers-color-scheme: light)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_light/tables-light.svg" width="12.5%">
  <img alt="æƒé‡å’Œåå·®è¡¨" src="/wandb/wandb/raw/main" style="visibility:visible;max-width:100%;" _mstalt="510926" _msthash="334">
</picture></themed-picture>
</a>
<a href="https://docs.wandb.ai/guides/sweeps?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow">
<themed-picture data-catalyst-inline="true" data-catalyst=""><picture>
  <source media="(prefers-color-scheme: dark)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_dark_background/sweeps-dark.svg" width="12.5%">
  <source media="(prefers-color-scheme: light)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_light/sweeps-light.svg" width="12.5%">
  <img alt="æƒé‡å’Œåå·®æ‰«æ" src="/wandb/wandb/raw/main" style="visibility:visible;max-width:100%;" _mstalt="519961" _msthash="335">
</picture></themed-picture>
</a>
<a href="https://docs.wandb.ai/guides/model_registry?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow">
<themed-picture data-catalyst-inline="true" data-catalyst=""><picture>
  <source media="(prefers-color-scheme: dark)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_dark_background/model-registry-dark.svg" width="12.5%">
  <source media="(prefers-color-scheme: light)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_light/model-registry-light.svg" width="12.5%">
  <img alt="æƒé‡å’Œåå·®æ¨¡å‹ç®¡ç†" src="/wandb/wandb/raw/main" style="visibility:visible;max-width:100%;" _mstalt="906256" _msthash="336">
</picture></themed-picture>
</a>
<a href="https://docs.wandb.ai/guides/artifacts/project-scoped-automations?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow">
<themed-picture data-catalyst-inline="true" data-catalyst=""><picture>
  <source media="(prefers-color-scheme: dark)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_dark_background/automations-dark.svg" width="12.5%">
  <source media="(prefers-color-scheme: light)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_light/automations-light.svg" width="12.5%">
  <img alt="æƒé‡å’Œåå·®æç¤º" src="/wandb/wandb/raw/main" style="visibility:visible;max-width:100%;" _mstalt="567177" _msthash="337">
</picture></themed-picture>
</a></p>
<p dir="auto" _msttexthash="212694261" _msthash="338">æŸ¥çœ‹<a href="https://docs.wandb.ai/?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=documentation" rel="nofollow" _istranslated="1">W&amp;Bå¼€å‘äººå‘˜æŒ‡å—</a>å’Œ<a href="https://docs.wandb.ai/ref?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=documentation" rel="nofollow" _istranslated="1">APIå‚è€ƒæŒ‡å—</a>ä»¥è·å–W&amp;Bå¹³å°çš„å®Œæ•´æŠ€æœ¯æè¿°ã€‚</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="13498394" _msthash="339">å¿«é€Ÿå…¥é—¨</h1><a id="user-content-quickstart" class="anchor" aria-label="æ°¸ä¹…é“¾æ¥ï¼šå¿«é€Ÿå…¥é—¨" href="#quickstart" _mstaria-label="446966" _msthash="340"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="58019416" _msthash="341">é€šè¿‡å››ä¸ªæ­¥éª¤å¼€å§‹ä½¿ç”¨ W&amp;Bï¼š</p>
<ol dir="auto">
<li>
<p dir="auto" _msttexthash="43429178" _msthash="342">é¦–å…ˆï¼Œæ³¨å†Œä¸€ä¸ª<a href="https://wandb.ai/login?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=quickstart" rel="nofollow" _istranslated="1">W&amp;Bè´¦æˆ·</a>ã€‚</p>
</li>
<li>
<p dir="auto" _msttexthash="209225471" _msthash="343">å…¶æ¬¡ï¼Œä½¿ç”¨ <a href="https://pip.pypa.io/en/stable/" rel="nofollow" _istranslated="1">pip</a> å®‰è£… W&amp;B SDKã€‚å¯¼èˆªåˆ°æ‚¨çš„ç»ˆç«¯å¹¶é”®å…¥ä»¥ä¸‹å‘½ä»¤ï¼š</p>
</li>
</ol>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre>pip install wandb</pre><div class="zeroclipboard-container">
  
  </div></div>
<ol start="3" dir="auto">
<li _msttexthash="32785805" _msthash="344">ç¬¬ä¸‰ï¼Œç™»å½•W&amp;Bï¼š</li>
</ol>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-s1">wandb</span>.<span class="pl-en">login</span>()</pre><div class="zeroclipboard-container">
   
  </div></div>
<ol start="4" dir="auto">
<li _msttexthash="224305393" _msthash="345">ä½¿ç”¨ä¸‹é¢çš„ç¤ºä¾‹ä»£ç ç‰‡æ®µä½œä¸ºæ¨¡æ¿ï¼Œå°† W&amp;B é›†æˆåˆ°æ‚¨çš„ Python è„šæœ¬ä¸­ï¼š</li>
</ol>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-k">import</span> <span class="pl-s1">wandb</span>

<span class="pl-c"># Start a W&amp;B Run with wandb.init</span>
<span class="pl-s1">run</span> <span class="pl-c1">=</span> <span class="pl-s1">wandb</span>.<span class="pl-en">init</span>(<span class="pl-s1">project</span><span class="pl-c1">=</span><span class="pl-s">"my_first_project"</span>)

<span class="pl-c"># Save model inputs and hyperparameters in a wandb.config object</span>
<span class="pl-s1">config</span> <span class="pl-c1">=</span> <span class="pl-s1">run</span>.<span class="pl-s1">config</span>
<span class="pl-s1">config</span>.<span class="pl-s1">learning_rate</span> <span class="pl-c1">=</span> <span class="pl-c1">0.01</span>

<span class="pl-c"># Model training code here ...</span>

<span class="pl-c"># Log metrics over time to visualize performance with wandb.log</span>
<span class="pl-k">for</span> <span class="pl-s1">i</span> <span class="pl-c1">in</span> <span class="pl-en">range</span>(<span class="pl-c1">10</span>):
    <span class="pl-s1">run</span>.<span class="pl-en">log</span>({<span class="pl-s">"loss"</span>: ...})

<span class="pl-c"># Mark the run as finished, and finish uploading all data</span>
<span class="pl-s1">run</span>.<span class="pl-en">finish</span>()</pre><div class="zeroclipboard-container">
   
  </div></div>
<p dir="auto" _msttexthash="1139676278" _msthash="346">å°±æ˜¯è¿™æ ·ï¼å¯¼èˆªåˆ°W&amp;Båº”ç”¨ç¨‹åºä»¥æŸ¥çœ‹æ‚¨çš„ç¬¬ä¸€ä¸ªW&amp;Bå®éªŒçš„ä»ªè¡¨æ¿ã€‚ä½¿ç”¨W&amp;Båº”ç”¨ç¨‹åºåœ¨ä¸€ä¸ªç»Ÿä¸€çš„åœ°æ–¹æ¯”è¾ƒå¤šä¸ªå®éªŒï¼Œæ·±å…¥ç ”ç©¶å•æ¬¡è¿è¡Œçš„ç»“æœï¼Œä»¥åŠæ›´å¤šï¼</p>
<p align="center" dir="auto" _msthidden="4">
<animated-image data-catalyst="" _msthidden="4" style="width: 100%;"><a target="_blank" rel="noopener noreferrer" href="https://github.com/wandb/wandb/blob/main/assets/wandb_demo_experiments.gif" data-target="animated-image.originalLink"><img src="https://github.com/wandb/wandb/raw/main/assets/wandb_demo_experiments.gif" style="max-width: 100%; display: inline-block;" data-target="animated-image.originalImage"></a>
      
</p>
<p align="center" dir="auto" _msttexthash="105285297" _msthash="351">æ˜¾ç¤ºå®éªŒä¸­çš„è¿è¡Œæ¬¡æ•°çš„ W&amp;B æ§åˆ¶é¢æ¿ç¤ºä¾‹ã€‚</p>
<p dir="auto">&nbsp;</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="6123234" _msthash="352">é›†æˆ</h1><a id="user-content-integrations" class="anchor" aria-label="æ°¸ä¹…é“¾æ¥ï¼š é›†æˆ" href="#integrations" _mstaria-label="521521" _msthash="353"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="1358784999" _msthash="354">å°†æ‚¨æœ€å–œæ¬¢çš„æ¡†æ¶ä¸ W&amp;B ç»“åˆä½¿ç”¨ï¼Œå¯ä»¥åœ¨ç°æœ‰é¡¹ç›®ä¸­å¿«é€Ÿè½»æ¾åœ°è®¾ç½®å®éªŒè·Ÿè¸ªå’Œæ•°æ®ç‰ˆæœ¬æ§åˆ¶ã€‚æœ‰å…³å¦‚ä½•å°† W&amp;B ä¸æ‚¨é€‰æ‹©çš„æ¡†æ¶é›†æˆçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… W&amp;B å¼€å‘äººå‘˜æŒ‡å—ä¸­çš„<a href="https://docs.wandb.ai/guides/integrations" rel="nofollow" _istranslated="1">é›†æˆç« èŠ‚</a>ã€‚</p>

<details>
<summary _msttexthash="20819747" _msthash="355">ğŸ”¥ PyTorch æ’ä»¶</summary>
<p dir="auto"><font _mstmutation="1" _msttexthash="738061584" _msthash="356">è°ƒç”¨å¹¶ä¼ å…¥ PyTorch æ¨¡å‹ä»¥è‡ªåŠ¨è®°å½•æ¢¯åº¦å¹¶å­˜å‚¨ç½‘ç»œæ‹“æ‰‘ã€‚æ¥ä¸‹æ¥ï¼Œç”¨äºè·Ÿè¸ªå…¶ä»–æŒ‡æ ‡ã€‚ä»¥ä¸‹ç¤ºä¾‹æ¼”ç¤ºäº†å¦‚ä½•æ‰§è¡Œæ­¤æ“ä½œçš„ç¤ºä¾‹ï¼š</font><code>.watch</code><code>.log</code></p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-k">import</span> <span class="pl-s1">wandb</span>

<span class="pl-c"># 1. Start a new run</span>
<span class="pl-s1">run</span> <span class="pl-c1">=</span> <span class="pl-s1">wandb</span>.<span class="pl-en">init</span>(<span class="pl-s1">project</span><span class="pl-c1">=</span><span class="pl-s">"gpt4"</span>)

<span class="pl-c"># 2. Save model inputs and hyperparameters</span>
<span class="pl-s1">config</span> <span class="pl-c1">=</span> <span class="pl-s1">run</span>.<span class="pl-s1">config</span>
<span class="pl-s1">config</span>.<span class="pl-s1">dropout</span> <span class="pl-c1">=</span> <span class="pl-c1">0.01</span>

<span class="pl-c"># 3. Log gradients and model parameters</span>
<span class="pl-s1">run</span>.<span class="pl-en">watch</span>(<span class="pl-s1">model</span>)
<span class="pl-k">for</span> <span class="pl-s1">batch_idx</span>, (<span class="pl-s1">data</span>, <span class="pl-s1">target</span>) <span class="pl-c1">in</span> <span class="pl-en">enumerate</span>(<span class="pl-s1">train_loader</span>):
    ...
    <span class="pl-k">if</span> <span class="pl-s1">batch_idx</span> <span class="pl-c1">%</span> <span class="pl-s1">args</span>.<span class="pl-s1">log_interval</span> <span class="pl-c1">==</span> <span class="pl-c1">0</span>:
        <span class="pl-c"># 4. Log metrics to visualize performance</span>
        <span class="pl-s1">run</span>.<span class="pl-en">log</span>({<span class="pl-s">"loss"</span>: <span class="pl-s1">loss</span>})</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="import wandb

# 1. Start a new run
run = wandb.init(project=&quot;gpt4&quot;)

# 2. Save model inputs and hyperparameters
config = run.config
config.dropout = 0.01

# 3. Log gradients and model parameters
run.watch(model)
for batch_idx, (data, target) in enumerate(train_loader):
    ...
    if batch_idx % args.log_interval == 0:
        # 4. Log metrics to visualize performance
        run.log({&quot;loss&quot;: loss})" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<ul dir="auto">
<li _msttexthash="18554107" _msthash="357">è¿è¡Œç¤ºä¾‹ <a href="http://wandb.me/pytorch-colab" rel="nofollow" _istranslated="1">Google Colab Notebook</a>ã€‚</li>
<li _msttexthash="214787157" _msthash="358">é˜…è¯»<a href="https://docs.wandb.com/guides/integrations/pytorch?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">å¼€å‘äººå‘˜æŒ‡å—</a>ä»¥è·å–æœ‰å…³å¦‚ä½•å°† PyTorch ä¸ W&amp;B é›†æˆçš„æŠ€æœ¯è¯¦ç»†ä¿¡æ¯ã€‚</li>
<li _msttexthash="15500069" _msthash="359">æ¢ç´¢ <a href="https://app.wandb.ai/wandb/getting-started/reports/Pytorch--VmlldzoyMTEwNzM?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">W&amp;B æŠ¥å‘Š</a>ã€‚</li>
</ul>
</details>
<details>
<summary _msttexthash="11316383" _msthash="360">ğŸŒŠ TensorFlow/Keras</summary><font _mstmutation="1" _msttexthash="218751988" _msthash="361">å½“æ‚¨åœ¨è®­ç»ƒæœŸé—´è°ƒç”¨ 'model.fit' æ—¶ï¼Œä½¿ç”¨ W&amp;B Callbacks è‡ªåŠ¨å°†æŒ‡æ ‡ä¿å­˜åˆ° W&amp;Bã€‚</font><p dir="auto" _msttexthash="162379399" _msthash="362">ä»¥ä¸‹ä»£ç ç¤ºä¾‹æ¼”ç¤ºäº†å°† W&amp;B ä¸ Keras é›†æˆæ—¶è„šæœ¬çš„å¤–è§‚ï¼š</p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"># This script needs these libraries to be installed:</span>
<span class="pl-c">#   tensorflow, numpy</span>

<span class="pl-k">import</span> <span class="pl-s1">wandb</span>
<span class="pl-k">from</span> <span class="pl-s1">wandb</span>.<span class="pl-s1">keras</span> <span class="pl-k">import</span> <span class="pl-v">WandbMetricsLogger</span>, <span class="pl-v">WandbModelCheckpoint</span>

<span class="pl-k">import</span> <span class="pl-s1">random</span>
<span class="pl-k">import</span> <span class="pl-s1">numpy</span> <span class="pl-k">as</span> <span class="pl-s1">np</span>
<span class="pl-k">import</span> <span class="pl-s1">tensorflow</span> <span class="pl-k">as</span> <span class="pl-s1">tf</span>


<span class="pl-c"># Start a run, tracking hyperparameters</span>
<span class="pl-s1">run</span> <span class="pl-c1">=</span> <span class="pl-s1">wandb</span>.<span class="pl-en">init</span>(
    <span class="pl-c"># set the wandb project where this run will be logged</span>
    <span class="pl-s1">project</span><span class="pl-c1">=</span><span class="pl-s">"my-awesome-project"</span>,
    <span class="pl-c"># track hyperparameters and run metadata with wandb.config</span>
    <span class="pl-s1">config</span><span class="pl-c1">=</span>{
        <span class="pl-s">"layer_1"</span>: <span class="pl-c1">512</span>,
        <span class="pl-s">"activation_1"</span>: <span class="pl-s">"relu"</span>,
        <span class="pl-s">"dropout"</span>: <span class="pl-s1">random</span>.<span class="pl-en">uniform</span>(<span class="pl-c1">0.01</span>, <span class="pl-c1">0.80</span>),
        <span class="pl-s">"layer_2"</span>: <span class="pl-c1">10</span>,
        <span class="pl-s">"activation_2"</span>: <span class="pl-s">"softmax"</span>,
        <span class="pl-s">"optimizer"</span>: <span class="pl-s">"sgd"</span>,
        <span class="pl-s">"loss"</span>: <span class="pl-s">"sparse_categorical_crossentropy"</span>,
        <span class="pl-s">"metric"</span>: <span class="pl-s">"accuracy"</span>,
        <span class="pl-s">"epoch"</span>: <span class="pl-c1">8</span>,
        <span class="pl-s">"batch_size"</span>: <span class="pl-c1">256</span>,
    },
)

<span class="pl-c"># [optional] use wandb.config as your config</span>
<span class="pl-s1">config</span> <span class="pl-c1">=</span> <span class="pl-s1">run</span>.<span class="pl-s1">config</span>

<span class="pl-c"># get the data</span>
<span class="pl-s1">mnist</span> <span class="pl-c1">=</span> <span class="pl-s1">tf</span>.<span class="pl-s1">keras</span>.<span class="pl-s1">datasets</span>.<span class="pl-s1">mnist</span>
(<span class="pl-s1">x_train</span>, <span class="pl-s1">y_train</span>), (<span class="pl-s1">x_test</span>, <span class="pl-s1">y_test</span>) <span class="pl-c1">=</span> <span class="pl-s1">mnist</span>.<span class="pl-en">load_data</span>()
<span class="pl-s1">x_train</span>, <span class="pl-s1">x_test</span> <span class="pl-c1">=</span> <span class="pl-s1">x_train</span> <span class="pl-c1">/</span> <span class="pl-c1">255.0</span>, <span class="pl-s1">x_test</span> <span class="pl-c1">/</span> <span class="pl-c1">255.0</span>
<span class="pl-s1">x_train</span>, <span class="pl-s1">y_train</span> <span class="pl-c1">=</span> <span class="pl-s1">x_train</span>[::<span class="pl-c1">5</span>], <span class="pl-s1">y_train</span>[::<span class="pl-c1">5</span>]
<span class="pl-s1">x_test</span>, <span class="pl-s1">y_test</span> <span class="pl-c1">=</span> <span class="pl-s1">x_test</span>[::<span class="pl-c1">20</span>], <span class="pl-s1">y_test</span>[::<span class="pl-c1">20</span>]
<span class="pl-s1">labels</span> <span class="pl-c1">=</span> [<span class="pl-en">str</span>(<span class="pl-s1">digit</span>) <span class="pl-k">for</span> <span class="pl-s1">digit</span> <span class="pl-c1">in</span> <span class="pl-en">range</span>(<span class="pl-s1">np</span>.<span class="pl-en">max</span>(<span class="pl-s1">y_train</span>) <span class="pl-c1">+</span> <span class="pl-c1">1</span>)]

<span class="pl-c"># build a model</span>
<span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-s1">tf</span>.<span class="pl-s1">keras</span>.<span class="pl-s1">models</span>.<span class="pl-v">Sequential</span>(
    [
        <span class="pl-s1">tf</span>.<span class="pl-s1">keras</span>.<span class="pl-s1">layers</span>.<span class="pl-v">Flatten</span>(<span class="pl-s1">input_shape</span><span class="pl-c1">=</span>(<span class="pl-c1">28</span>, <span class="pl-c1">28</span>)),
        <span class="pl-s1">tf</span>.<span class="pl-s1">keras</span>.<span class="pl-s1">layers</span>.<span class="pl-v">Dense</span>(<span class="pl-s1">config</span>.<span class="pl-s1">layer_1</span>, <span class="pl-s1">activation</span><span class="pl-c1">=</span><span class="pl-s1">config</span>.<span class="pl-s1">activation_1</span>),
        <span class="pl-s1">tf</span>.<span class="pl-s1">keras</span>.<span class="pl-s1">layers</span>.<span class="pl-v">Dropout</span>(<span class="pl-s1">config</span>.<span class="pl-s1">dropout</span>),
        <span class="pl-s1">tf</span>.<span class="pl-s1">keras</span>.<span class="pl-s1">layers</span>.<span class="pl-v">Dense</span>(<span class="pl-s1">config</span>.<span class="pl-s1">layer_2</span>, <span class="pl-s1">activation</span><span class="pl-c1">=</span><span class="pl-s1">config</span>.<span class="pl-s1">activation_2</span>),
    ]
)

<span class="pl-c"># compile the model</span>
<span class="pl-s1">model</span>.<span class="pl-en">compile</span>(<span class="pl-s1">optimizer</span><span class="pl-c1">=</span><span class="pl-s1">config</span>.<span class="pl-s1">optimizer</span>, <span class="pl-s1">loss</span><span class="pl-c1">=</span><span class="pl-s1">config</span>.<span class="pl-s1">loss</span>, <span class="pl-s1">metrics</span><span class="pl-c1">=</span>[<span class="pl-s1">config</span>.<span class="pl-s1">metric</span>])

<span class="pl-c"># WandbMetricsLogger will log train and validation metrics to wandb</span>
<span class="pl-c"># WandbModelCheckpoint will upload model checkpoints to wandb</span>
<span class="pl-s1">history</span> <span class="pl-c1">=</span> <span class="pl-s1">model</span>.<span class="pl-en">fit</span>(
    <span class="pl-s1">x</span><span class="pl-c1">=</span><span class="pl-s1">x_train</span>,
    <span class="pl-s1">y</span><span class="pl-c1">=</span><span class="pl-s1">y_train</span>,
    <span class="pl-s1">epochs</span><span class="pl-c1">=</span><span class="pl-s1">config</span>.<span class="pl-s1">epoch</span>,
    <span class="pl-s1">batch_size</span><span class="pl-c1">=</span><span class="pl-s1">config</span>.<span class="pl-s1">batch_size</span>,
    <span class="pl-s1">validation_data</span><span class="pl-c1">=</span>(<span class="pl-s1">x_test</span>, <span class="pl-s1">y_test</span>),
    <span class="pl-s1">callbacks</span><span class="pl-c1">=</span>[
        <span class="pl-v">WandbMetricsLogger</span>(<span class="pl-s1">log_freq</span><span class="pl-c1">=</span><span class="pl-c1">5</span>),
        <span class="pl-v">WandbModelCheckpoint</span>(<span class="pl-s">"models"</span>),
    ],
)

<span class="pl-c"># [optional] finish the wandb run, necessary in notebooks</span>
<span class="pl-s1">run</span>.<span class="pl-en">finish</span>()</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# This script needs these libraries to be installed:
#   tensorflow, numpy

import wandb
from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint

import random
import numpy as np
import tensorflow as tf


# Start a run, tracking hyperparameters
run = wandb.init(
    # set the wandb project where this run will be logged
    project=&quot;my-awesome-project&quot;,
    # track hyperparameters and run metadata with wandb.config
    config={
        &quot;layer_1&quot;: 512,
        &quot;activation_1&quot;: &quot;relu&quot;,
        &quot;dropout&quot;: random.uniform(0.01, 0.80),
        &quot;layer_2&quot;: 10,
        &quot;activation_2&quot;: &quot;softmax&quot;,
        &quot;optimizer&quot;: &quot;sgd&quot;,
        &quot;loss&quot;: &quot;sparse_categorical_crossentropy&quot;,
        &quot;metric&quot;: &quot;accuracy&quot;,
        &quot;epoch&quot;: 8,
        &quot;batch_size&quot;: 256,
    },
)

# [optional] use wandb.config as your config
config = run.config

# get the data
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
x_train, y_train = x_train[::5], y_train[::5]
x_test, y_test = x_test[::20], y_test[::20]
labels = [str(digit) for digit in range(np.max(y_train) + 1)]

# build a model
model = tf.keras.models.Sequential(
    [
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(config.layer_1, activation=config.activation_1),
        tf.keras.layers.Dropout(config.dropout),
        tf.keras.layers.Dense(config.layer_2, activation=config.activation_2),
    ]
)

# compile the model
model.compile(optimizer=config.optimizer, loss=config.loss, metrics=[config.metric])

# WandbMetricsLogger will log train and validation metrics to wandb
# WandbModelCheckpoint will upload model checkpoints to wandb
history = model.fit(
    x=x_train,
    y=y_train,
    epochs=config.epoch,
    batch_size=config.batch_size,
    validation_data=(x_test, y_test),
    callbacks=[
        WandbMetricsLogger(log_freq=5),
        WandbModelCheckpoint(&quot;models&quot;),
    ],
)

# [optional] finish the wandb run, necessary in notebooks
run.finish()" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<p dir="auto" _msttexthash="85379242" _msthash="363">ç«‹å³å¼€å§‹å°†æ‚¨çš„ Keras æ¨¡å‹ä¸ W&amp;B é›†æˆï¼š</p>
<ul dir="auto">
<li _msttexthash="13761007" _msthash="364">è¿è¡Œç¤ºä¾‹ <a href="https://wandb.me/intro-keras?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">Google Colab Notebook</a></li>
<li _msttexthash="216148673" _msthash="365">é˜…è¯»<a href="https://docs.wandb.com/guides/integrations/keras?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">å¼€å‘äººå‘˜æŒ‡å—</a>ï¼Œäº†è§£æœ‰å…³å¦‚ä½•å°† Keras ä¸ W&amp;B é›†æˆçš„æŠ€æœ¯è¯¦ç»†ä¿¡æ¯ã€‚</li>
<li _msttexthash="15500069" _msthash="366">æ¢ç´¢ <a href="https://app.wandb.ai/wandb/getting-started/reports/Keras--VmlldzoyMTEwNjQ?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">W&amp;B æŠ¥å‘Š</a>ã€‚</li>
</ul>
</details>
<details>
<summary _msttexthash="28865876" _msthash="367">ğŸ¤— Hugging Face å˜å‹å™¨</summary>
<p dir="auto"><font _mstmutation="1" _msttexthash="508856322" _msthash="368">åœ¨ä½¿ç”¨ Hugging Face Trainer è¿è¡Œè„šæœ¬æ—¶ä¼ é€’ç»™å‚æ•°ã€‚W&amp;Bå°†è‡ªåŠ¨è®°å½•æŸå¤±ï¼Œ
è¯„ä¼°æŒ‡æ ‡ã€æ¨¡å‹æ‹“æ‰‘å’Œæ¢¯åº¦ã€‚</font><code>wandb</code><code>report_to</code></p>
<p dir="auto"><font _mstmutation="1" _msttexthash="95880083" _msthash="369"><strong _mstmutation="1" _istranslated="1">æ³¨æ„</strong>ï¼šæ‚¨è¿è¡Œè„šæœ¬çš„ç¯å¢ƒå¿…é¡»å·²å®‰è£…ã€‚</font><code>wandb</code></p>
<p dir="auto" _msttexthash="96825716" _msthash="370">ä»¥ä¸‹ç¤ºä¾‹æ¼”ç¤ºäº†å¦‚ä½•å°† W&amp;B ä¸ Hugging Face é›†æˆï¼š</p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"># This script needs these libraries to be installed:</span>
<span class="pl-c">#   numpy, transformers, datasets</span>

<span class="pl-k">import</span> <span class="pl-s1">wandb</span>

<span class="pl-k">import</span> <span class="pl-s1">os</span>
<span class="pl-k">import</span> <span class="pl-s1">numpy</span> <span class="pl-k">as</span> <span class="pl-s1">np</span>
<span class="pl-k">from</span> <span class="pl-s1">datasets</span> <span class="pl-k">import</span> <span class="pl-s1">load_dataset</span>
<span class="pl-k">from</span> <span class="pl-s1">transformers</span> <span class="pl-k">import</span> <span class="pl-v">TrainingArguments</span>, <span class="pl-v">Trainer</span>
<span class="pl-k">from</span> <span class="pl-s1">transformers</span> <span class="pl-k">import</span> <span class="pl-v">AutoTokenizer</span>, <span class="pl-v">AutoModelForSequenceClassification</span>


<span class="pl-k">def</span> <span class="pl-en">tokenize_function</span>(<span class="pl-s1">examples</span>):
    <span class="pl-k">return</span> <span class="pl-en">tokenizer</span>(<span class="pl-s1">examples</span>[<span class="pl-s">"text"</span>], <span class="pl-s1">padding</span><span class="pl-c1">=</span><span class="pl-s">"max_length"</span>, <span class="pl-s1">truncation</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)


<span class="pl-k">def</span> <span class="pl-en">compute_metrics</span>(<span class="pl-s1">eval_pred</span>):
    <span class="pl-s1">logits</span>, <span class="pl-s1">labels</span> <span class="pl-c1">=</span> <span class="pl-s1">eval_pred</span>
    <span class="pl-s1">predictions</span> <span class="pl-c1">=</span> <span class="pl-s1">np</span>.<span class="pl-en">argmax</span>(<span class="pl-s1">logits</span>, <span class="pl-s1">axis</span><span class="pl-c1">=</span><span class="pl-c1">-</span><span class="pl-c1">1</span>)
    <span class="pl-k">return</span> {<span class="pl-s">"accuracy"</span>: <span class="pl-s1">np</span>.<span class="pl-en">mean</span>(<span class="pl-s1">predictions</span> <span class="pl-c1">==</span> <span class="pl-s1">labels</span>)}


<span class="pl-c"># download prepare the data</span>
<span class="pl-s1">dataset</span> <span class="pl-c1">=</span> <span class="pl-en">load_dataset</span>(<span class="pl-s">"yelp_review_full"</span>)
<span class="pl-s1">tokenizer</span> <span class="pl-c1">=</span> <span class="pl-v">AutoTokenizer</span>.<span class="pl-en">from_pretrained</span>(<span class="pl-s">"distilbert-base-uncased"</span>)

<span class="pl-s1">small_train_dataset</span> <span class="pl-c1">=</span> <span class="pl-s1">dataset</span>[<span class="pl-s">"train"</span>].<span class="pl-en">shuffle</span>(<span class="pl-s1">seed</span><span class="pl-c1">=</span><span class="pl-c1">42</span>).<span class="pl-en">select</span>(<span class="pl-en">range</span>(<span class="pl-c1">1000</span>))
<span class="pl-s1">small_eval_dataset</span> <span class="pl-c1">=</span> <span class="pl-s1">dataset</span>[<span class="pl-s">"test"</span>].<span class="pl-en">shuffle</span>(<span class="pl-s1">seed</span><span class="pl-c1">=</span><span class="pl-c1">42</span>).<span class="pl-en">select</span>(<span class="pl-en">range</span>(<span class="pl-c1">300</span>))

<span class="pl-s1">small_train_dataset</span> <span class="pl-c1">=</span> <span class="pl-s1">small_train_dataset</span>.<span class="pl-en">map</span>(<span class="pl-s1">tokenize_function</span>, <span class="pl-s1">batched</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)
<span class="pl-s1">small_eval_dataset</span> <span class="pl-c1">=</span> <span class="pl-s1">small_train_dataset</span>.<span class="pl-en">map</span>(<span class="pl-s1">tokenize_function</span>, <span class="pl-s1">batched</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)

<span class="pl-c"># download the model</span>
<span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-v">AutoModelForSequenceClassification</span>.<span class="pl-en">from_pretrained</span>(
    <span class="pl-s">"distilbert-base-uncased"</span>, <span class="pl-s1">num_labels</span><span class="pl-c1">=</span><span class="pl-c1">5</span>
)

<span class="pl-c"># set the wandb project where this run will be logged</span>
<span class="pl-s1">os</span>.<span class="pl-s1">environ</span>[<span class="pl-s">"WANDB_PROJECT"</span>] <span class="pl-c1">=</span> <span class="pl-s">"my-awesome-project"</span>

<span class="pl-c"># save your trained model checkpoint to wandb</span>
<span class="pl-s1">os</span>.<span class="pl-s1">environ</span>[<span class="pl-s">"WANDB_LOG_MODEL"</span>] <span class="pl-c1">=</span> <span class="pl-s">"true"</span>

<span class="pl-c"># turn off watch to log faster</span>
<span class="pl-s1">os</span>.<span class="pl-s1">environ</span>[<span class="pl-s">"WANDB_WATCH"</span>] <span class="pl-c1">=</span> <span class="pl-s">"false"</span>

<span class="pl-c"># pass "wandb" to the `report_to` parameter to turn on wandb logging</span>
<span class="pl-s1">training_args</span> <span class="pl-c1">=</span> <span class="pl-v">TrainingArguments</span>(
    <span class="pl-s1">output_dir</span><span class="pl-c1">=</span><span class="pl-s">"models"</span>,
    <span class="pl-s1">report_to</span><span class="pl-c1">=</span><span class="pl-s">"wandb"</span>,
    <span class="pl-s1">logging_steps</span><span class="pl-c1">=</span><span class="pl-c1">5</span>,
    <span class="pl-s1">per_device_train_batch_size</span><span class="pl-c1">=</span><span class="pl-c1">32</span>,
    <span class="pl-s1">per_device_eval_batch_size</span><span class="pl-c1">=</span><span class="pl-c1">32</span>,
    <span class="pl-s1">evaluation_strategy</span><span class="pl-c1">=</span><span class="pl-s">"steps"</span>,
    <span class="pl-s1">eval_steps</span><span class="pl-c1">=</span><span class="pl-c1">20</span>,
    <span class="pl-s1">max_steps</span><span class="pl-c1">=</span><span class="pl-c1">100</span>,
    <span class="pl-s1">save_steps</span><span class="pl-c1">=</span><span class="pl-c1">100</span>,
)

<span class="pl-c"># define the trainer and start training</span>
<span class="pl-s1">trainer</span> <span class="pl-c1">=</span> <span class="pl-v">Trainer</span>(
    <span class="pl-s1">model</span><span class="pl-c1">=</span><span class="pl-s1">model</span>,
    <span class="pl-s1">args</span><span class="pl-c1">=</span><span class="pl-s1">training_args</span>,
    <span class="pl-s1">train_dataset</span><span class="pl-c1">=</span><span class="pl-s1">small_train_dataset</span>,
    <span class="pl-s1">eval_dataset</span><span class="pl-c1">=</span><span class="pl-s1">small_eval_dataset</span>,
    <span class="pl-s1">compute_metrics</span><span class="pl-c1">=</span><span class="pl-s1">compute_metrics</span>,
)
<span class="pl-s1">trainer</span>.<span class="pl-en">train</span>()

<span class="pl-c"># [optional] finish the wandb run, necessary in notebooks</span>
<span class="pl-s1">wandb</span>.<span class="pl-en">finish</span>()</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# This script needs these libraries to be installed:
#   numpy, transformers, datasets

import wandb

import os
import numpy as np
from datasets import load_dataset
from transformers import TrainingArguments, Trainer
from transformers import AutoTokenizer, AutoModelForSequenceClassification


def tokenize_function(examples):
    return tokenizer(examples[&quot;text&quot;], padding=&quot;max_length&quot;, truncation=True)


def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return {&quot;accuracy&quot;: np.mean(predictions == labels)}


# download prepare the data
dataset = load_dataset(&quot;yelp_review_full&quot;)
tokenizer = AutoTokenizer.from_pretrained(&quot;distilbert-base-uncased&quot;)

small_train_dataset = dataset[&quot;train&quot;].shuffle(seed=42).select(range(1000))
small_eval_dataset = dataset[&quot;test&quot;].shuffle(seed=42).select(range(300))

small_train_dataset = small_train_dataset.map(tokenize_function, batched=True)
small_eval_dataset = small_train_dataset.map(tokenize_function, batched=True)

# download the model
model = AutoModelForSequenceClassification.from_pretrained(
    &quot;distilbert-base-uncased&quot;, num_labels=5
)

# set the wandb project where this run will be logged
os.environ[&quot;WANDB_PROJECT&quot;] = &quot;my-awesome-project&quot;

# save your trained model checkpoint to wandb
os.environ[&quot;WANDB_LOG_MODEL&quot;] = &quot;true&quot;

# turn off watch to log faster
os.environ[&quot;WANDB_WATCH&quot;] = &quot;false&quot;

# pass &quot;wandb&quot; to the `report_to` parameter to turn on wandb logging
training_args = TrainingArguments(
    output_dir=&quot;models&quot;,
    report_to=&quot;wandb&quot;,
    logging_steps=5,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    evaluation_strategy=&quot;steps&quot;,
    eval_steps=20,
    max_steps=100,
    save_steps=100,
)

# define the trainer and start training
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)
trainer.train()

# [optional] finish the wandb run, necessary in notebooks
wandb.finish()" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<ul dir="auto">
<li _msttexthash="18554107" _msthash="371">è¿è¡Œç¤ºä¾‹ <a href="http://wandb.me/hf?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">Google Colab Notebook</a>ã€‚</li>
<li _msttexthash="175086340" _msthash="372">é˜…è¯»<a href="https://docs.wandb.com/guides/integrations/huggingface?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">å¼€å‘è€…æŒ‡å—</a>ä»¥è·å–å¦‚ä½•å°†Hugging Faceä¸W&amp;Bé›†æˆçš„æŠ€æœ¯ç»†èŠ‚ã€‚</li>
</ul>
</details>
<details>
<summary _msttexthash="22389666" _msthash="373">âš¡ï¸ PyTorch é—ªç”µ</summary>
<p dir="auto" _msttexthash="296488959" _msthash="374">ä½¿ç”¨ Lightning æ„å»ºå¯æ‰©å±•ã€ç»“æ„åŒ–ã€é«˜æ€§èƒ½çš„ PyTorch æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨ W&amp;B è®°å½•å®ƒä»¬ã€‚</p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"># This script needs these libraries to be installed:</span>
<span class="pl-c">#   torch, torchvision, pytorch_lightning</span>

<span class="pl-k">import</span> <span class="pl-s1">wandb</span>

<span class="pl-k">import</span> <span class="pl-s1">os</span>
<span class="pl-k">from</span> <span class="pl-s1">torch</span> <span class="pl-k">import</span> <span class="pl-s1">optim</span>, <span class="pl-s1">nn</span>, <span class="pl-s1">utils</span>
<span class="pl-k">from</span> <span class="pl-s1">torchvision</span>.<span class="pl-s1">datasets</span> <span class="pl-k">import</span> <span class="pl-v">MNIST</span>
<span class="pl-k">from</span> <span class="pl-s1">torchvision</span>.<span class="pl-s1">transforms</span> <span class="pl-k">import</span> <span class="pl-v">ToTensor</span>

<span class="pl-k">import</span> <span class="pl-s1">pytorch_lightning</span> <span class="pl-k">as</span> <span class="pl-s1">pl</span>
<span class="pl-k">from</span> <span class="pl-s1">pytorch_lightning</span>.<span class="pl-s1">loggers</span> <span class="pl-k">import</span> <span class="pl-v">WandbLogger</span>


<span class="pl-k">class</span> <span class="pl-v">LitAutoEncoder</span>(<span class="pl-s1">pl</span>.<span class="pl-v">LightningModule</span>):
    <span class="pl-k">def</span> <span class="pl-en">__init__</span>(<span class="pl-s1">self</span>, <span class="pl-s1">lr</span><span class="pl-c1">=</span><span class="pl-c1">1e-3</span>, <span class="pl-s1">inp_size</span><span class="pl-c1">=</span><span class="pl-c1">28</span>, <span class="pl-s1">optimizer</span><span class="pl-c1">=</span><span class="pl-s">"Adam"</span>):
        <span class="pl-en">super</span>().<span class="pl-en">__init__</span>()

        <span class="pl-s1">self</span>.<span class="pl-s1">encoder</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">Sequential</span>(
            <span class="pl-s1">nn</span>.<span class="pl-v">Linear</span>(<span class="pl-s1">inp_size</span> <span class="pl-c1">*</span> <span class="pl-s1">inp_size</span>, <span class="pl-c1">64</span>), <span class="pl-s1">nn</span>.<span class="pl-v">ReLU</span>(), <span class="pl-s1">nn</span>.<span class="pl-v">Linear</span>(<span class="pl-c1">64</span>, <span class="pl-c1">3</span>)
        )
        <span class="pl-s1">self</span>.<span class="pl-s1">decoder</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">Sequential</span>(
            <span class="pl-s1">nn</span>.<span class="pl-v">Linear</span>(<span class="pl-c1">3</span>, <span class="pl-c1">64</span>), <span class="pl-s1">nn</span>.<span class="pl-v">ReLU</span>(), <span class="pl-s1">nn</span>.<span class="pl-v">Linear</span>(<span class="pl-c1">64</span>, <span class="pl-s1">inp_size</span> <span class="pl-c1">*</span> <span class="pl-s1">inp_size</span>)
        )
        <span class="pl-s1">self</span>.<span class="pl-s1">lr</span> <span class="pl-c1">=</span> <span class="pl-s1">lr</span>

        <span class="pl-c"># save hyperparameters to self.hparamsm auto-logged by wandb</span>
        <span class="pl-s1">self</span>.<span class="pl-en">save_hyperparameters</span>()

    <span class="pl-k">def</span> <span class="pl-en">training_step</span>(<span class="pl-s1">self</span>, <span class="pl-s1">batch</span>, <span class="pl-s1">batch_idx</span>):
        <span class="pl-s1">x</span>, <span class="pl-s1">y</span> <span class="pl-c1">=</span> <span class="pl-s1">batch</span>
        <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">x</span>.<span class="pl-en">view</span>(<span class="pl-s1">x</span>.<span class="pl-en">size</span>(<span class="pl-c1">0</span>), <span class="pl-c1">-</span><span class="pl-c1">1</span>)
        <span class="pl-s1">z</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">encoder</span>(<span class="pl-s1">x</span>)
        <span class="pl-s1">x_hat</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">decoder</span>(<span class="pl-s1">z</span>)
        <span class="pl-s1">loss</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-s1">functional</span>.<span class="pl-en">mse_loss</span>(<span class="pl-s1">x_hat</span>, <span class="pl-s1">x</span>)

        <span class="pl-c"># log metrics to wandb</span>
        <span class="pl-s1">self</span>.<span class="pl-en">log</span>(<span class="pl-s">"train_loss"</span>, <span class="pl-s1">loss</span>)
        <span class="pl-k">return</span> <span class="pl-s1">loss</span>

    <span class="pl-k">def</span> <span class="pl-en">configure_optimizers</span>(<span class="pl-s1">self</span>):
        <span class="pl-s1">optimizer</span> <span class="pl-c1">=</span> <span class="pl-s1">optim</span>.<span class="pl-v">Adam</span>(<span class="pl-s1">self</span>.<span class="pl-en">parameters</span>(), <span class="pl-s1">lr</span><span class="pl-c1">=</span><span class="pl-s1">self</span>.<span class="pl-s1">lr</span>)
        <span class="pl-k">return</span> <span class="pl-s1">optimizer</span>


<span class="pl-c"># init the autoencoder</span>
<span class="pl-s1">autoencoder</span> <span class="pl-c1">=</span> <span class="pl-v">LitAutoEncoder</span>(<span class="pl-s1">lr</span><span class="pl-c1">=</span><span class="pl-c1">1e-3</span>, <span class="pl-s1">inp_size</span><span class="pl-c1">=</span><span class="pl-c1">28</span>)

<span class="pl-c"># setup data</span>
<span class="pl-s1">batch_size</span> <span class="pl-c1">=</span> <span class="pl-c1">32</span>
<span class="pl-s1">dataset</span> <span class="pl-c1">=</span> <span class="pl-v">MNIST</span>(<span class="pl-s1">os</span>.<span class="pl-en">getcwd</span>(), <span class="pl-s1">download</span><span class="pl-c1">=</span><span class="pl-c1">True</span>, <span class="pl-s1">transform</span><span class="pl-c1">=</span><span class="pl-v">ToTensor</span>())
<span class="pl-s1">train_loader</span> <span class="pl-c1">=</span> <span class="pl-s1">utils</span>.<span class="pl-s1">data</span>.<span class="pl-v">DataLoader</span>(<span class="pl-s1">dataset</span>, <span class="pl-s1">shuffle</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)

<span class="pl-c"># initialise the wandb logger and name your wandb project</span>
<span class="pl-s1">wandb_logger</span> <span class="pl-c1">=</span> <span class="pl-v">WandbLogger</span>(<span class="pl-s1">project</span><span class="pl-c1">=</span><span class="pl-s">"my-awesome-project"</span>)

<span class="pl-c"># add your batch size to the wandb config</span>
<span class="pl-s1">wandb_logger</span>.<span class="pl-s1">experiment</span>.<span class="pl-s1">config</span>[<span class="pl-s">"batch_size"</span>] <span class="pl-c1">=</span> <span class="pl-s1">batch_size</span>

<span class="pl-c"># pass wandb_logger to the Trainer</span>
<span class="pl-s1">trainer</span> <span class="pl-c1">=</span> <span class="pl-s1">pl</span>.<span class="pl-v">Trainer</span>(<span class="pl-s1">limit_train_batches</span><span class="pl-c1">=</span><span class="pl-c1">750</span>, <span class="pl-s1">max_epochs</span><span class="pl-c1">=</span><span class="pl-c1">5</span>, <span class="pl-s1">logger</span><span class="pl-c1">=</span><span class="pl-s1">wandb_logger</span>)

<span class="pl-c"># train the model</span>
<span class="pl-s1">trainer</span>.<span class="pl-en">fit</span>(<span class="pl-s1">model</span><span class="pl-c1">=</span><span class="pl-s1">autoencoder</span>, <span class="pl-s1">train_dataloaders</span><span class="pl-c1">=</span><span class="pl-s1">train_loader</span>)

<span class="pl-c"># [optional] finish the wandb run, necessary in notebooks</span>
<span class="pl-s1">wandb</span>.<span class="pl-en">finish</span>()</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# This script needs these libraries to be installed:
#   torch, torchvision, pytorch_lightning

import wandb

import os
from torch import optim, nn, utils
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor

import pytorch_lightning as pl
from pytorch_lightning.loggers import WandbLogger


class LitAutoEncoder(pl.LightningModule):
    def __init__(self, lr=1e-3, inp_size=28, optimizer=&quot;Adam&quot;):
        super().__init__()

        self.encoder = nn.Sequential(
            nn.Linear(inp_size * inp_size, 64), nn.ReLU(), nn.Linear(64, 3)
        )
        self.decoder = nn.Sequential(
            nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, inp_size * inp_size)
        )
        self.lr = lr

        # save hyperparameters to self.hparamsm auto-logged by wandb
        self.save_hyperparameters()

    def training_step(self, batch, batch_idx):
        x, y = batch
        x = x.view(x.size(0), -1)
        z = self.encoder(x)
        x_hat = self.decoder(z)
        loss = nn.functional.mse_loss(x_hat, x)

        # log metrics to wandb
        self.log(&quot;train_loss&quot;, loss)
        return loss

    def configure_optimizers(self):
        optimizer = optim.Adam(self.parameters(), lr=self.lr)
        return optimizer


# init the autoencoder
autoencoder = LitAutoEncoder(lr=1e-3, inp_size=28)

# setup data
batch_size = 32
dataset = MNIST(os.getcwd(), download=True, transform=ToTensor())
train_loader = utils.data.DataLoader(dataset, shuffle=True)

# initialise the wandb logger and name your wandb project
wandb_logger = WandbLogger(project=&quot;my-awesome-project&quot;)

# add your batch size to the wandb config
wandb_logger.experiment.config[&quot;batch_size&quot;] = batch_size

# pass wandb_logger to the Trainer
trainer = pl.Trainer(limit_train_batches=750, max_epochs=5, logger=wandb_logger)

# train the model
trainer.fit(model=autoencoder, train_dataloaders=train_loader)

# [optional] finish the wandb run, necessary in notebooks
wandb.finish()" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<ul dir="auto">
<li _msttexthash="18554107" _msthash="375">è¿è¡Œç¤ºä¾‹ <a href="http://wandb.me/lightning?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">Google Colab Notebook</a>ã€‚</li>
<li _msttexthash="258330176" _msthash="376">é˜…è¯»<a href="https://docs.wandb.ai/guides/integrations/lightning?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">å¼€å‘äººå‘˜æŒ‡å—</a>ï¼Œäº†è§£æœ‰å…³å¦‚ä½•å°†PyTorch Lightningä¸W&amp;Bé›†æˆçš„æŠ€æœ¯è¯¦ç»†ä¿¡æ¯ã€‚</li>
</ul>
</details>
<details>
<summary _msttexthash="11020828" _msthash="377">ğŸ’¨ XGBoost</summary><font _mstmutation="1" _msttexthash="218751988" _msthash="378">å½“æ‚¨åœ¨è®­ç»ƒæœŸé—´è°ƒç”¨ 'model.fit' æ—¶ï¼Œä½¿ç”¨ W&amp;B Callbacks è‡ªåŠ¨å°†æŒ‡æ ‡ä¿å­˜åˆ° W&amp;Bã€‚</font><p dir="auto" _msttexthash="170320254" _msthash="379">ä»¥ä¸‹ä»£ç ç¤ºä¾‹æ¼”ç¤ºäº†å°† W&amp;B ä¸ XGBoost é›†æˆæ—¶è„šæœ¬çš„å¤–è§‚ï¼š</p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"># This script needs these libraries to be installed:</span>
<span class="pl-c">#   numpy, xgboost</span>

<span class="pl-k">import</span> <span class="pl-s1">wandb</span>
<span class="pl-k">from</span> <span class="pl-s1">wandb</span>.<span class="pl-s1">xgboost</span> <span class="pl-k">import</span> <span class="pl-v">WandbCallback</span>

<span class="pl-k">import</span> <span class="pl-s1">numpy</span> <span class="pl-k">as</span> <span class="pl-s1">np</span>
<span class="pl-k">import</span> <span class="pl-s1">xgboost</span> <span class="pl-k">as</span> <span class="pl-s1">xgb</span>


<span class="pl-c"># setup parameters for xgboost</span>
<span class="pl-s1">param</span> <span class="pl-c1">=</span> {
    <span class="pl-s">"objective"</span>: <span class="pl-s">"multi:softmax"</span>,
    <span class="pl-s">"eta"</span>: <span class="pl-c1">0.1</span>,
    <span class="pl-s">"max_depth"</span>: <span class="pl-c1">6</span>,
    <span class="pl-s">"nthread"</span>: <span class="pl-c1">4</span>,
    <span class="pl-s">"num_class"</span>: <span class="pl-c1">6</span>,
}

<span class="pl-c"># start a new wandb run to track this script</span>
<span class="pl-s1">run</span> <span class="pl-c1">=</span> <span class="pl-s1">wandb</span>.<span class="pl-en">init</span>(
    <span class="pl-c"># set the wandb project where this run will be logged</span>
    <span class="pl-s1">project</span><span class="pl-c1">=</span><span class="pl-s">"my-awesome-project"</span>,
    <span class="pl-c"># track hyperparameters and run metadata</span>
    <span class="pl-s1">config</span><span class="pl-c1">=</span><span class="pl-s1">param</span>,
)

<span class="pl-c"># download data from wandb Artifacts and prep data</span>
<span class="pl-s1">run</span>.<span class="pl-en">use_artifact</span>(<span class="pl-s">"wandb/intro/dermatology_data:v0"</span>, <span class="pl-s1">type</span><span class="pl-c1">=</span><span class="pl-s">"dataset"</span>).<span class="pl-en">download</span>(<span class="pl-s">"."</span>)
<span class="pl-s1">data</span> <span class="pl-c1">=</span> <span class="pl-s1">np</span>.<span class="pl-en">loadtxt</span>(
    <span class="pl-s">"./dermatology.data"</span>,
    <span class="pl-s1">delimiter</span><span class="pl-c1">=</span><span class="pl-s">","</span>,
    <span class="pl-s1">converters</span><span class="pl-c1">=</span>{<span class="pl-c1">33</span>: <span class="pl-k">lambda</span> <span class="pl-s1">x</span>: <span class="pl-en">int</span>(<span class="pl-s1">x</span> <span class="pl-c1">==</span> <span class="pl-s">"?"</span>), <span class="pl-c1">34</span>: <span class="pl-k">lambda</span> <span class="pl-s1">x</span>: <span class="pl-en">int</span>(<span class="pl-s1">x</span>) <span class="pl-c1">-</span> <span class="pl-c1">1</span>},
)
<span class="pl-s1">sz</span> <span class="pl-c1">=</span> <span class="pl-s1">data</span>.<span class="pl-s1">shape</span>

<span class="pl-s1">train</span> <span class="pl-c1">=</span> <span class="pl-s1">data</span>[: <span class="pl-en">int</span>(<span class="pl-s1">sz</span>[<span class="pl-c1">0</span>] <span class="pl-c1">*</span> <span class="pl-c1">0.7</span>), :]
<span class="pl-s1">test</span> <span class="pl-c1">=</span> <span class="pl-s1">data</span>[<span class="pl-en">int</span>(<span class="pl-s1">sz</span>[<span class="pl-c1">0</span>] <span class="pl-c1">*</span> <span class="pl-c1">0.7</span>) :, :]

<span class="pl-s1">train_X</span> <span class="pl-c1">=</span> <span class="pl-s1">train</span>[:, :<span class="pl-c1">33</span>]
<span class="pl-s1">train_Y</span> <span class="pl-c1">=</span> <span class="pl-s1">train</span>[:, <span class="pl-c1">34</span>]

<span class="pl-s1">test_X</span> <span class="pl-c1">=</span> <span class="pl-s1">test</span>[:, :<span class="pl-c1">33</span>]
<span class="pl-s1">test_Y</span> <span class="pl-c1">=</span> <span class="pl-s1">test</span>[:, <span class="pl-c1">34</span>]

<span class="pl-s1">xg_train</span> <span class="pl-c1">=</span> <span class="pl-s1">xgb</span>.<span class="pl-v">DMatrix</span>(<span class="pl-s1">train_X</span>, <span class="pl-s1">label</span><span class="pl-c1">=</span><span class="pl-s1">train_Y</span>)
<span class="pl-s1">xg_test</span> <span class="pl-c1">=</span> <span class="pl-s1">xgb</span>.<span class="pl-v">DMatrix</span>(<span class="pl-s1">test_X</span>, <span class="pl-s1">label</span><span class="pl-c1">=</span><span class="pl-s1">test_Y</span>)
<span class="pl-s1">watchlist</span> <span class="pl-c1">=</span> [(<span class="pl-s1">xg_train</span>, <span class="pl-s">"train"</span>), (<span class="pl-s1">xg_test</span>, <span class="pl-s">"test"</span>)]

<span class="pl-c"># add another config to the wandb run</span>
<span class="pl-s1">num_round</span> <span class="pl-c1">=</span> <span class="pl-c1">5</span>
<span class="pl-s1">run</span>.<span class="pl-s1">config</span>[<span class="pl-s">"num_round"</span>] <span class="pl-c1">=</span> <span class="pl-c1">5</span>
<span class="pl-s1">run</span>.<span class="pl-s1">config</span>[<span class="pl-s">"data_shape"</span>] <span class="pl-c1">=</span> <span class="pl-s1">sz</span>

<span class="pl-c"># pass WandbCallback to the booster to log its configs and metrics</span>
<span class="pl-s1">bst</span> <span class="pl-c1">=</span> <span class="pl-s1">xgb</span>.<span class="pl-en">train</span>(
    <span class="pl-s1">param</span>, <span class="pl-s1">xg_train</span>, <span class="pl-s1">num_round</span>, <span class="pl-s1">evals</span><span class="pl-c1">=</span><span class="pl-s1">watchlist</span>, <span class="pl-s1">callbacks</span><span class="pl-c1">=</span>[<span class="pl-v">WandbCallback</span>()]
)

<span class="pl-c"># get prediction</span>
<span class="pl-s1">pred</span> <span class="pl-c1">=</span> <span class="pl-s1">bst</span>.<span class="pl-en">predict</span>(<span class="pl-s1">xg_test</span>)
<span class="pl-s1">error_rate</span> <span class="pl-c1">=</span> <span class="pl-s1">np</span>.<span class="pl-en">sum</span>(<span class="pl-s1">pred</span> <span class="pl-c1">!=</span> <span class="pl-s1">test_Y</span>) <span class="pl-c1">/</span> <span class="pl-s1">test_Y</span>.<span class="pl-s1">shape</span>[<span class="pl-c1">0</span>]

<span class="pl-c"># log your test metric to wandb</span>
<span class="pl-s1">run</span>.<span class="pl-s1">summary</span>[<span class="pl-s">"Error Rate"</span>] <span class="pl-c1">=</span> <span class="pl-s1">error_rate</span>

<span class="pl-c"># [optional] finish the wandb run, necessary in notebooks</span>
<span class="pl-s1">run</span>.<span class="pl-en">finish</span>()</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# This script needs these libraries to be installed:
#   numpy, xgboost

import wandb
from wandb.xgboost import WandbCallback

import numpy as np
import xgboost as xgb


# setup parameters for xgboost
param = {
    &quot;objective&quot;: &quot;multi:softmax&quot;,
    &quot;eta&quot;: 0.1,
    &quot;max_depth&quot;: 6,
    &quot;nthread&quot;: 4,
    &quot;num_class&quot;: 6,
}

# start a new wandb run to track this script
run = wandb.init(
    # set the wandb project where this run will be logged
    project=&quot;my-awesome-project&quot;,
    # track hyperparameters and run metadata
    config=param,
)

# download data from wandb Artifacts and prep data
run.use_artifact(&quot;wandb/intro/dermatology_data:v0&quot;, type=&quot;dataset&quot;).download(&quot;.&quot;)
data = np.loadtxt(
    &quot;./dermatology.data&quot;,
    delimiter=&quot;,&quot;,
    converters={33: lambda x: int(x == &quot;?&quot;), 34: lambda x: int(x) - 1},
)
sz = data.shape

train = data[: int(sz[0] * 0.7), :]
test = data[int(sz[0] * 0.7) :, :]

train_X = train[:, :33]
train_Y = train[:, 34]

test_X = test[:, :33]
test_Y = test[:, 34]

xg_train = xgb.DMatrix(train_X, label=train_Y)
xg_test = xgb.DMatrix(test_X, label=test_Y)
watchlist = [(xg_train, &quot;train&quot;), (xg_test, &quot;test&quot;)]

# add another config to the wandb run
num_round = 5
run.config[&quot;num_round&quot;] = 5
run.config[&quot;data_shape&quot;] = sz

# pass WandbCallback to the booster to log its configs and metrics
bst = xgb.train(
    param, xg_train, num_round, evals=watchlist, callbacks=[WandbCallback()]
)

# get prediction
pred = bst.predict(xg_test)
error_rate = np.sum(pred != test_Y) / test_Y.shape[0]

# log your test metric to wandb
run.summary[&quot;Error Rate&quot;] = error_rate

# [optional] finish the wandb run, necessary in notebooks
run.finish()" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<ul dir="auto">
<li _msttexthash="18554107" _msthash="380">è¿è¡Œç¤ºä¾‹ <a href="https://wandb.me/xgboost?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">Google Colab Notebook</a>ã€‚</li>
<li _msttexthash="206345776" _msthash="381">é˜…è¯»<a href="https://docs.wandb.ai/guides/integrations/xgboost?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">å¼€å‘è€…æŒ‡å—</a>ä»¥è·å–æœ‰å…³å¦‚ä½•å°†XGBoostä¸W&amp;Bé›†æˆçš„æŠ€æœ¯è¯¦ç»†ä¿¡æ¯ã€‚</li>
</ul>
</details>
<details>
<summary _msttexthash="20346183" _msthash="382">ğŸ§® Sci-Kit å­¦ä¹ </summary><font _mstmutation="1" _msttexthash="133372564" _msthash="383">ä½¿ç”¨ wandb å¯è§†åŒ–å’Œæ¯”è¾ƒ scikit-learn æ¨¡å‹çš„æ€§èƒ½ï¼š</font><div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"># This script needs these libraries to be installed:</span>
<span class="pl-c">#   numpy, sklearn</span>

<span class="pl-k">import</span> <span class="pl-s1">wandb</span>
<span class="pl-k">from</span> <span class="pl-s1">wandb</span>.<span class="pl-s1">sklearn</span> <span class="pl-k">import</span> <span class="pl-s1">plot_precision_recall</span>, <span class="pl-s1">plot_feature_importances</span>
<span class="pl-k">from</span> <span class="pl-s1">wandb</span>.<span class="pl-s1">sklearn</span> <span class="pl-k">import</span> <span class="pl-s1">plot_class_proportions</span>, <span class="pl-s1">plot_learning_curve</span>, <span class="pl-s1">plot_roc</span>

<span class="pl-k">import</span> <span class="pl-s1">numpy</span> <span class="pl-k">as</span> <span class="pl-s1">np</span>
<span class="pl-k">from</span> <span class="pl-s1">sklearn</span> <span class="pl-k">import</span> <span class="pl-s1">datasets</span>
<span class="pl-k">from</span> <span class="pl-s1">sklearn</span>.<span class="pl-s1">ensemble</span> <span class="pl-k">import</span> <span class="pl-v">RandomForestClassifier</span>
<span class="pl-k">from</span> <span class="pl-s1">sklearn</span>.<span class="pl-s1">model_selection</span> <span class="pl-k">import</span> <span class="pl-s1">train_test_split</span>


<span class="pl-c"># load and process data</span>
<span class="pl-s1">wbcd</span> <span class="pl-c1">=</span> <span class="pl-s1">datasets</span>.<span class="pl-en">load_breast_cancer</span>()
<span class="pl-s1">feature_names</span> <span class="pl-c1">=</span> <span class="pl-s1">wbcd</span>.<span class="pl-s1">feature_names</span>
<span class="pl-s1">labels</span> <span class="pl-c1">=</span> <span class="pl-s1">wbcd</span>.<span class="pl-s1">target_names</span>

<span class="pl-s1">test_size</span> <span class="pl-c1">=</span> <span class="pl-c1">0.2</span>
<span class="pl-v">X_train</span>, <span class="pl-v">X_test</span>, <span class="pl-s1">y_train</span>, <span class="pl-s1">y_test</span> <span class="pl-c1">=</span> <span class="pl-en">train_test_split</span>(
    <span class="pl-s1">wbcd</span>.<span class="pl-s1">data</span>, <span class="pl-s1">wbcd</span>.<span class="pl-s1">target</span>, <span class="pl-s1">test_size</span><span class="pl-c1">=</span><span class="pl-s1">test_size</span>
)

<span class="pl-c"># train model</span>
<span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-v">RandomForestClassifier</span>()
<span class="pl-s1">model</span>.<span class="pl-en">fit</span>(<span class="pl-v">X_train</span>, <span class="pl-s1">y_train</span>)
<span class="pl-s1">model_params</span> <span class="pl-c1">=</span> <span class="pl-s1">model</span>.<span class="pl-en">get_params</span>()

<span class="pl-c"># get predictions</span>
<span class="pl-s1">y_pred</span> <span class="pl-c1">=</span> <span class="pl-s1">model</span>.<span class="pl-en">predict</span>(<span class="pl-v">X_test</span>)
<span class="pl-s1">y_probas</span> <span class="pl-c1">=</span> <span class="pl-s1">model</span>.<span class="pl-en">predict_proba</span>(<span class="pl-v">X_test</span>)
<span class="pl-s1">importances</span> <span class="pl-c1">=</span> <span class="pl-s1">model</span>.<span class="pl-s1">feature_importances_</span>
<span class="pl-s1">indices</span> <span class="pl-c1">=</span> <span class="pl-s1">np</span>.<span class="pl-en">argsort</span>(<span class="pl-s1">importances</span>)[::<span class="pl-c1">-</span><span class="pl-c1">1</span>]

<span class="pl-c"># start a new wandb run and add your model hyperparameters</span>
<span class="pl-s1">run</span> <span class="pl-c1">=</span> <span class="pl-s1">wandb</span>.<span class="pl-en">init</span>(<span class="pl-s1">project</span><span class="pl-c1">=</span><span class="pl-s">"my-awesome-project"</span>, <span class="pl-s1">config</span><span class="pl-c1">=</span><span class="pl-s1">model_params</span>)

<span class="pl-c"># Add additional configs to wandb</span>
<span class="pl-s1">run</span>.<span class="pl-s1">config</span>.<span class="pl-en">update</span>(
    {
        <span class="pl-s">"test_size"</span>: <span class="pl-s1">test_size</span>,
        <span class="pl-s">"train_len"</span>: <span class="pl-en">len</span>(<span class="pl-v">X_train</span>),
        <span class="pl-s">"test_len"</span>: <span class="pl-en">len</span>(<span class="pl-v">X_test</span>),
    }
)

<span class="pl-c"># log additional visualisations to wandb</span>
<span class="pl-en">plot_class_proportions</span>(<span class="pl-s1">y_train</span>, <span class="pl-s1">y_test</span>, <span class="pl-s1">labels</span>)
<span class="pl-en">plot_learning_curve</span>(<span class="pl-s1">model</span>, <span class="pl-v">X_train</span>, <span class="pl-s1">y_train</span>)
<span class="pl-en">plot_roc</span>(<span class="pl-s1">y_test</span>, <span class="pl-s1">y_probas</span>, <span class="pl-s1">labels</span>)
<span class="pl-en">plot_precision_recall</span>(<span class="pl-s1">y_test</span>, <span class="pl-s1">y_probas</span>, <span class="pl-s1">labels</span>)
<span class="pl-en">plot_feature_importances</span>(<span class="pl-s1">model</span>)

<span class="pl-c"># [optional] finish the wandb run, necessary in notebooks</span>
<span class="pl-s1">run</span>.<span class="pl-en">finish</span>()</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# This script needs these libraries to be installed:
#   numpy, sklearn

import wandb
from wandb.sklearn import plot_precision_recall, plot_feature_importances
from wandb.sklearn import plot_class_proportions, plot_learning_curve, plot_roc

import numpy as np
from sklearn import datasets
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split


# load and process data
wbcd = datasets.load_breast_cancer()
feature_names = wbcd.feature_names
labels = wbcd.target_names

test_size = 0.2
X_train, X_test, y_train, y_test = train_test_split(
    wbcd.data, wbcd.target, test_size=test_size
)

# train model
model = RandomForestClassifier()
model.fit(X_train, y_train)
model_params = model.get_params()

# get predictions
y_pred = model.predict(X_test)
y_probas = model.predict_proba(X_test)
importances = model.feature_importances_
indices = np.argsort(importances)[::-1]

# start a new wandb run and add your model hyperparameters
run = wandb.init(project=&quot;my-awesome-project&quot;, config=model_params)

# Add additional configs to wandb
run.config.update(
    {
        &quot;test_size&quot;: test_size,
        &quot;train_len&quot;: len(X_train),
        &quot;test_len&quot;: len(X_test),
    }
)

# log additional visualisations to wandb
plot_class_proportions(y_train, y_test, labels)
plot_learning_curve(model, X_train, y_train)
plot_roc(y_test, y_probas, labels)
plot_precision_recall(y_test, y_probas, labels)
plot_feature_importances(model)

# [optional] finish the wandb run, necessary in notebooks
run.finish()" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<ul dir="auto">
<li _msttexthash="18554107" _msthash="384">è¿è¡Œç¤ºä¾‹ <a href="https://wandb.me/scikit-colab?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">Google Colab Notebook</a>ã€‚</li>
<li _msttexthash="242944936" _msthash="385">é˜…è¯»<a href="https://docs.wandb.ai/guides/integrations/scikit?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">å¼€å‘äººå‘˜æŒ‡å—</a>ï¼Œäº†è§£æœ‰å…³å¦‚ä½•å°† Scikit-Learn ä¸ W&amp;B é›†æˆçš„æŠ€æœ¯è¯¦ç»†ä¿¡æ¯ã€‚</li>
</ul>
</details>
<p dir="auto">&nbsp;</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="20167043" _msthash="386">W&amp;B æ‰˜ç®¡é€‰é¡¹</h1><a id="user-content-wb-hosting-options" class="anchor" aria-label="æ°¸ä¹…é“¾æ¥ï¼šW&amp;B æ‰˜ç®¡é€‰é¡¹" href="#wb-hosting-options" _mstaria-label="884195" _msthash="387"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="708580197" _msthash="388">Weights &amp; Biaseså¯ä»¥åœ¨äº‘ä¸­ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥å®‰è£…åœ¨æ‚¨çš„ç§æœ‰åŸºç¡€è®¾æ–½ä¸Šã€‚é€šè¿‡ä»¥ä¸‹ä¸‰ç§æ–¹å¼ä¹‹ä¸€åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è®¾ç½®W&amp;BæœåŠ¡å™¨ï¼š</p>
<ol dir="auto">
<li _msttexthash="367878368" _msthash="389"><a href="https://docs.wandb.ai/guides/hosting/hosting-options/self-managed#on-prem-private-cloud?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=hosting" rel="nofollow" _istranslated="1">ç”Ÿäº§äº‘</a>ï¼šä½¿ç”¨ W&amp;B æä¾›çš„ terraform è„šæœ¬ï¼Œåªéœ€å‡ ä¸ªæ­¥éª¤å³å¯åœ¨ç§æœ‰äº‘ä¸Šè®¾ç½®ç”Ÿäº§éƒ¨ç½²ã€‚</li>
<li _msttexthash="317635955" _msthash="390"><a href="https://docs.wandb.ai/guides/hosting/hosting-options/wb-managed#dedicated-cloud?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=hosting" rel="nofollow" _istranslated="1">ä¸“ç”¨äº‘</a>ï¼šåœ¨æ‚¨é€‰æ‹©çš„äº‘åŒºåŸŸä¸­ï¼Œåœ¨ W&amp;B çš„å•ç§Ÿæˆ·åŸºç¡€è®¾æ–½ä¸Šè¿›è¡Œæ‰˜ç®¡çš„ä¸“ç”¨éƒ¨ç½²ã€‚</li>
<li><font _mstmutation="1" _msttexthash="858068003" _msthash="391"><a href="https://docs.wandb.ai/guides/hosting/how-to-guides/bare-metal?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=hosting" rel="nofollow" _mstmutation="1" _istranslated="1">æœ¬åœ°/è£¸æœº</a>ï¼šW&amp;Bæ”¯æŒåœ¨æ‚¨çš„æœ¬åœ°æ•°æ®ä¸­å¿ƒçš„å¤§å¤šæ•°è£¸æœºæœåŠ¡å™¨ä¸Šè®¾ç½®ç”Ÿäº§æœåŠ¡å™¨ã€‚é€šè¿‡è·‘æ­¥å¿«é€Ÿå¼€å§‹ï¼Œè½»æ¾å¼€å§‹åœ¨æ‚¨çš„æœ¬åœ°åŸºç¡€è®¾æ–½ä¸Šæ‰˜ç®¡W&amp;Bã€‚</font><code>wandb server</code></li>
</ol>
<p dir="auto" _msttexthash="150934953" _msthash="392">æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… W&amp;B å¼€å‘äººå‘˜æŒ‡å—ä¸­çš„<a href="https://docs.wandb.ai/guides/hosting?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=hosting" rel="nofollow" _istranslated="1">æ‰˜ç®¡æ–‡æ¡£</a>ã€‚</p>

<p dir="auto">&nbsp;</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="20154082" _msthash="393">Python ç‰ˆæœ¬æ”¯æŒ</h1><a id="user-content-python-version-support" class="anchor" aria-label="æ°¸ä¹…é“¾æ¥ï¼šPython ç‰ˆæœ¬æ”¯æŒ" href="#python-version-support" _mstaria-label="891410" _msthash="394"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="857095928" _msthash="395">æˆ‘ä»¬æ‰¿è¯ºåœ¨ Python è½¯ä»¶åŸºé‡‘ä¼šå®šä¹‰çš„æ­£å¼ç”Ÿå‘½å‘¨æœŸç»ˆæ­¢ ï¼ˆEOLï¼‰ æ—¥æœŸå<em _istranslated="1">è‡³å°‘</em>å…­ä¸ªæœˆå†…æ”¯æŒæˆ‘ä»¬æ‰€éœ€çš„æœ€ä½ Python ç‰ˆæœ¬ã€‚æ‚¨å¯ä»¥<a href="https://devguide.python.org/versions/" rel="nofollow" _istranslated="1">åœ¨æ­¤å¤„</a>æ‰¾åˆ° Python EOL æ—¥æœŸåˆ—è¡¨ã€‚</p>
<p dir="auto" _msttexthash="301956304" _msthash="396">å½“æˆ‘ä»¬åœæ­¢å¯¹ Python ç‰ˆæœ¬çš„æ”¯æŒæ—¶ï¼Œæˆ‘ä»¬å°†é€’å¢åº“çš„æ¬¡è¦ç‰ˆæœ¬å·ä»¥åæ˜ æ­¤æ›´æ”¹ã€‚</p>
<p dir="auto">&nbsp;</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="11535771" _msthash="397">è´¡çŒ®å‡†åˆ™</h1><a id="user-content-contribution-guidelines" class="anchor" aria-label="æ°¸ä¹…é“¾æ¥ï¼šè´¡çŒ®æŒ‡å—" href="#contribution-guidelines" _mstaria-label="988052" _msthash="398"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="1340181102" _msthash="399">Weights &amp; Biases â¤ï¸å¼€æºï¼Œæˆ‘ä»¬æ¬¢è¿ç¤¾åŒºçš„è´¡çŒ®ï¼æœ‰å…³å¼€å‘å·¥ä½œæµç¨‹å’Œ wandb åº“å†…éƒ¨çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…<a href="https://github.com/wandb/wandb/blob/main/CONTRIBUTING.md" _istranslated="1">è´¡çŒ®æŒ‡å—</a>ã€‚æœ‰å…³ wandb é”™è¯¯å’ŒåŠŸèƒ½è¯·æ±‚ï¼Œè¯·è®¿é—® <a href="https://github.com/wandb/wandb/issues" _istranslated="1">GitHub é—®é¢˜</a>æˆ–è”ç³» <a href="mailto:support@wandb.com" _istranslated="1">support@wandb.com</a>ã€‚</p>
<p dir="auto">&nbsp;</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="7101289" _msthash="400">W&amp;B ç¤¾åŒº</h1><a id="user-content-wb-community" class="anchor" aria-label="æ°¸ä¹…é“¾æ¥ï¼šW&amp;B ç¤¾åŒº" href="#wb-community" _mstaria-label="648479" _msthash="401"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="592882264" _msthash="402">æˆä¸ºä¸æ–­å¢é•¿çš„W&amp;Bç¤¾åŒºçš„ä¸€éƒ¨åˆ†ï¼Œå¹¶åœ¨æˆ‘ä»¬çš„<a href="https://wandb.me/discord" rel="nofollow" _istranslated="1">Discord</a>ä¸­ä¸W&amp;Bå›¢é˜Ÿäº’åŠ¨ã€‚é€šè¿‡<a href="https://wandb.ai/fully-connected" rel="nofollow" _istranslated="1">W&amp;B Fully Connected</a>ä¸æœ€æ–°çš„MLæ›´æ–°å’Œæ•™ç¨‹ä¿æŒè”ç³»ã€‚</p>
<p dir="auto">&nbsp;</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="9675445" _msthash="403">è®¸å¯è¯</h1><a id="user-content-license" class="anchor" aria-label="æ°¸ä¹…é“¾æ¥ï¼šè®¸å¯è¯" href="#license" _mstaria-label="331903" _msthash="404"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a href="https://github.com/wandb/wandb/blob/main/LICENSE" _msttexthash="13328120" _msthash="405">MIT è®¸å¯è¯</a></p>
</article></div>
