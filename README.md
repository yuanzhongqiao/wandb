<div class="Box-sc-g0xbh4-0 QkQOb js-snippet-clipboard-copy-unpositioned" data-hpc="true"><article class="markdown-body entry-content container-lg" itemprop="text"><p align="center" dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/wandb/wandb/blob/main/assets/logo-dark.svg#gh-dark-mode-only" _msthidden="1"><img src="https://github.com/wandb/wandb/raw/main/assets/logo-dark.svg#gh-dark-mode-only" width="600" alt="Weights &amp; Biases" style="max-width: 100%;" _msthidden="A" _mstalt="352612" _msthash="325"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/wandb/wandb/blob/main/assets/logo-light.svg#gh-light-mode-only"><img src="https://github.com/wandb/wandb/raw/main/assets/logo-light.svg#gh-light-mode-only" width="600" alt="权重和偏差" style="max-width: 100%;" _mstalt="352612" _msthash="326"></a>
</p>
<p align="center" dir="auto">
<a href="https://pypi.python.org/pypi/wandb" rel="nofollow"><img src="https://camo.githubusercontent.com/dd40995ddde5aa05b24ba55c3b232cbd09f2e0baca6bb824903059189a9d6f05/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f77616e6462" data-canonical-src="https://img.shields.io/pypi/v/wandb" style="max-width: 100%;"></a>
<a href="https://anaconda.org/conda-forge/wandb" rel="nofollow"><img src="https://camo.githubusercontent.com/d6debbd567284c2299c655117d81fd58eb3c082ad7285c20b7ad98c86331a8bb/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f77616e6462" data-canonical-src="https://img.shields.io/conda/vn/conda-forge/wandb" style="max-width: 100%;"></a>
<a href="https://pypi.python.org/pypi/wandb" rel="nofollow"><img src="https://camo.githubusercontent.com/648a89bbc5bf63a375b7ed6b0700a01d9e636491c3bc25591f516384fd7be91d/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f77616e6462" data-canonical-src="https://img.shields.io/pypi/pyversions/wandb" style="max-width: 100%;"></a>
<a href="https://circleci.com/gh/wandb/wandb" rel="nofollow"><img src="https://camo.githubusercontent.com/3e96d8ddcfdd1010c035c6eabce4c9e30afbce8749a71e370ac005ea247c1e50/68747470733a2f2f696d672e736869656c64732e696f2f636972636c6563692f6275696c642f6769746875622f77616e64622f77616e64622f6d61696e" data-canonical-src="https://img.shields.io/circleci/build/github/wandb/wandb/main" style="max-width: 100%;"></a>
<a href="https://codecov.io/gh/wandb/wandb" rel="nofollow"><img src="https://camo.githubusercontent.com/328774a44fcf3abcf8e10a6f471bfbc24cf95d23933c9150a73366ce4e243627/68747470733a2f2f696d672e736869656c64732e696f2f636f6465636f762f632f67682f77616e64622f77616e6462" data-canonical-src="https://img.shields.io/codecov/c/gh/wandb/wandb" style="max-width: 100%;"></a>
</p>
<p align="center" dir="auto">
<a href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_%26_Biases.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg" style="max-width: 100%;"></a>
</p>
<p dir="auto" _msttexthash="915794451" _msthash="327">使用W&amp;B更快地构建更好的模型。跟踪和可视化机器学习管道的所有部分，从数据集到生产机器学习模型。今天就开始使用W&amp;B吧，<a href="https://wandb.com?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow" _istranslated="1">注册一个W&amp;B账户吧！</a></p>
<br>
<p dir="auto" _msttexthash="393671499" _msthash="328">构建 LLM 应用程序？使用我们面向 GenAI 的新工具套件 <a href="https://wandb.github.io/weave?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow" _istranslated="1">Weave</a> 跟踪、调试、评估和监控 LLM 应用程序。</p>
<p dir="auto">&nbsp;</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="5144373" _msthash="329">文档</h1><a id="user-content-documentation" class="anchor" aria-label="永久链接： 文档" href="#documentation" _mstaria-label="559767" _msthash="330"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p align="center" dir="auto">
<a href="https://docs.wandb.ai/guides/track?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow">
<themed-picture data-catalyst-inline="true" data-catalyst=""><picture>
  <source media="(prefers-color-scheme: dark)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_dark_background/experiments-dark.svg" width="12.5%">
  <source media="(prefers-color-scheme: light)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_light/experiments-light.svg" width="12.5%">
  <img alt="权重和偏差实验" src="/wandb/wandb/raw/main" style="visibility:visible;max-width:100%;" _mstalt="739128" _msthash="331">
</picture></themed-picture>
</a>
<a href="https://docs.wandb.ai/guides/reports?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow">
<themed-picture data-catalyst-inline="true" data-catalyst=""><picture>
  <source media="(prefers-color-scheme: dark)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_dark_background/reports-dark.svg" width="12.5%">
  <source media="(prefers-color-scheme: light)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_light/reports-light.svg" width="12.5%">
  <img alt="权重和偏差报告" src="/wandb/wandb/raw/main" style="visibility:visible;max-width:100%;" _mstalt="565422" _msthash="332">
</picture></themed-picture>
</a>
<a href="https://docs.wandb.ai/guides/artifacts?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow">
<themed-picture data-catalyst-inline="true" data-catalyst=""><picture>
  <source media="(prefers-color-scheme: dark)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_dark_background/artifacts-dark.svg" width="12.5%">
  <source media="(prefers-color-scheme: light)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_light/artifacts-light.svg" width="12.5%">
  <img alt="Weights and Biases 伪影" src="/wandb/wandb/raw/main" style="visibility:visible;max-width:100%;" _mstalt="638092" _msthash="333">
</picture></themed-picture>
</a>
<a href="https://docs.wandb.ai/guides/tables?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow">
<themed-picture data-catalyst-inline="true" data-catalyst=""><picture>
  <source media="(prefers-color-scheme: dark)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_dark_background/tables-dark.svg" width="12.5%">
  <source media="(prefers-color-scheme: light)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_light/tables-light.svg" width="12.5%">
  <img alt="权重和偏差表" src="/wandb/wandb/raw/main" style="visibility:visible;max-width:100%;" _mstalt="510926" _msthash="334">
</picture></themed-picture>
</a>
<a href="https://docs.wandb.ai/guides/sweeps?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow">
<themed-picture data-catalyst-inline="true" data-catalyst=""><picture>
  <source media="(prefers-color-scheme: dark)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_dark_background/sweeps-dark.svg" width="12.5%">
  <source media="(prefers-color-scheme: light)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_light/sweeps-light.svg" width="12.5%">
  <img alt="权重和偏差扫描" src="/wandb/wandb/raw/main" style="visibility:visible;max-width:100%;" _mstalt="519961" _msthash="335">
</picture></themed-picture>
</a>
<a href="https://docs.wandb.ai/guides/model_registry?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow">
<themed-picture data-catalyst-inline="true" data-catalyst=""><picture>
  <source media="(prefers-color-scheme: dark)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_dark_background/model-registry-dark.svg" width="12.5%">
  <source media="(prefers-color-scheme: light)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_light/model-registry-light.svg" width="12.5%">
  <img alt="权重和偏差模型管理" src="/wandb/wandb/raw/main" style="visibility:visible;max-width:100%;" _mstalt="906256" _msthash="336">
</picture></themed-picture>
</a>
<a href="https://docs.wandb.ai/guides/artifacts/project-scoped-automations?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=readme" rel="nofollow">
<themed-picture data-catalyst-inline="true" data-catalyst=""><picture>
  <source media="(prefers-color-scheme: dark)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_dark_background/automations-dark.svg" width="12.5%">
  <source media="(prefers-color-scheme: light)" srcset="/wandb/wandb/raw/main/assets/Product_Icons_light/automations-light.svg" width="12.5%">
  <img alt="权重和偏差提示" src="/wandb/wandb/raw/main" style="visibility:visible;max-width:100%;" _mstalt="567177" _msthash="337">
</picture></themed-picture>
</a></p>
<p dir="auto" _msttexthash="212694261" _msthash="338">查看<a href="https://docs.wandb.ai/?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=documentation" rel="nofollow" _istranslated="1">W&amp;B开发人员指南</a>和<a href="https://docs.wandb.ai/ref?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=documentation" rel="nofollow" _istranslated="1">API参考指南</a>以获取W&amp;B平台的完整技术描述。</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="13498394" _msthash="339">快速入门</h1><a id="user-content-quickstart" class="anchor" aria-label="永久链接：快速入门" href="#quickstart" _mstaria-label="446966" _msthash="340"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="58019416" _msthash="341">通过四个步骤开始使用 W&amp;B：</p>
<ol dir="auto">
<li>
<p dir="auto" _msttexthash="43429178" _msthash="342">首先，注册一个<a href="https://wandb.ai/login?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=quickstart" rel="nofollow" _istranslated="1">W&amp;B账户</a>。</p>
</li>
<li>
<p dir="auto" _msttexthash="209225471" _msthash="343">其次，使用 <a href="https://pip.pypa.io/en/stable/" rel="nofollow" _istranslated="1">pip</a> 安装 W&amp;B SDK。导航到您的终端并键入以下命令：</p>
</li>
</ol>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre>pip install wandb</pre><div class="zeroclipboard-container">
  
  </div></div>
<ol start="3" dir="auto">
<li _msttexthash="32785805" _msthash="344">第三，登录W&amp;B：</li>
</ol>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-s1">wandb</span>.<span class="pl-en">login</span>()</pre><div class="zeroclipboard-container">
   
  </div></div>
<ol start="4" dir="auto">
<li _msttexthash="224305393" _msthash="345">使用下面的示例代码片段作为模板，将 W&amp;B 集成到您的 Python 脚本中：</li>
</ol>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-k">import</span> <span class="pl-s1">wandb</span>

<span class="pl-c"># Start a W&amp;B Run with wandb.init</span>
<span class="pl-s1">run</span> <span class="pl-c1">=</span> <span class="pl-s1">wandb</span>.<span class="pl-en">init</span>(<span class="pl-s1">project</span><span class="pl-c1">=</span><span class="pl-s">"my_first_project"</span>)

<span class="pl-c"># Save model inputs and hyperparameters in a wandb.config object</span>
<span class="pl-s1">config</span> <span class="pl-c1">=</span> <span class="pl-s1">run</span>.<span class="pl-s1">config</span>
<span class="pl-s1">config</span>.<span class="pl-s1">learning_rate</span> <span class="pl-c1">=</span> <span class="pl-c1">0.01</span>

<span class="pl-c"># Model training code here ...</span>

<span class="pl-c"># Log metrics over time to visualize performance with wandb.log</span>
<span class="pl-k">for</span> <span class="pl-s1">i</span> <span class="pl-c1">in</span> <span class="pl-en">range</span>(<span class="pl-c1">10</span>):
    <span class="pl-s1">run</span>.<span class="pl-en">log</span>({<span class="pl-s">"loss"</span>: ...})

<span class="pl-c"># Mark the run as finished, and finish uploading all data</span>
<span class="pl-s1">run</span>.<span class="pl-en">finish</span>()</pre><div class="zeroclipboard-container">
   
  </div></div>
<p dir="auto" _msttexthash="1139676278" _msthash="346">就是这样！导航到W&amp;B应用程序以查看您的第一个W&amp;B实验的仪表板。使用W&amp;B应用程序在一个统一的地方比较多个实验，深入研究单次运行的结果，以及更多！</p>
<p align="center" dir="auto" _msthidden="4">
<animated-image data-catalyst="" _msthidden="4" style="width: 100%;"><a target="_blank" rel="noopener noreferrer" href="https://github.com/wandb/wandb/blob/main/assets/wandb_demo_experiments.gif" data-target="animated-image.originalLink"><img src="https://github.com/wandb/wandb/raw/main/assets/wandb_demo_experiments.gif" style="max-width: 100%; display: inline-block;" data-target="animated-image.originalImage"></a>
      
</p>
<p align="center" dir="auto" _msttexthash="105285297" _msthash="351">显示实验中的运行次数的 W&amp;B 控制面板示例。</p>
<p dir="auto">&nbsp;</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="6123234" _msthash="352">集成</h1><a id="user-content-integrations" class="anchor" aria-label="永久链接： 集成" href="#integrations" _mstaria-label="521521" _msthash="353"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="1358784999" _msthash="354">将您最喜欢的框架与 W&amp;B 结合使用，可以在现有项目中快速轻松地设置实验跟踪和数据版本控制。有关如何将 W&amp;B 与您选择的框架集成的更多信息，请参阅 W&amp;B 开发人员指南中的<a href="https://docs.wandb.ai/guides/integrations" rel="nofollow" _istranslated="1">集成章节</a>。</p>

<details>
<summary _msttexthash="20819747" _msthash="355">🔥 PyTorch 插件</summary>
<p dir="auto"><font _mstmutation="1" _msttexthash="738061584" _msthash="356">调用并传入 PyTorch 模型以自动记录梯度并存储网络拓扑。接下来，用于跟踪其他指标。以下示例演示了如何执行此操作的示例：</font><code>.watch</code><code>.log</code></p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-k">import</span> <span class="pl-s1">wandb</span>

<span class="pl-c"># 1. Start a new run</span>
<span class="pl-s1">run</span> <span class="pl-c1">=</span> <span class="pl-s1">wandb</span>.<span class="pl-en">init</span>(<span class="pl-s1">project</span><span class="pl-c1">=</span><span class="pl-s">"gpt4"</span>)

<span class="pl-c"># 2. Save model inputs and hyperparameters</span>
<span class="pl-s1">config</span> <span class="pl-c1">=</span> <span class="pl-s1">run</span>.<span class="pl-s1">config</span>
<span class="pl-s1">config</span>.<span class="pl-s1">dropout</span> <span class="pl-c1">=</span> <span class="pl-c1">0.01</span>

<span class="pl-c"># 3. Log gradients and model parameters</span>
<span class="pl-s1">run</span>.<span class="pl-en">watch</span>(<span class="pl-s1">model</span>)
<span class="pl-k">for</span> <span class="pl-s1">batch_idx</span>, (<span class="pl-s1">data</span>, <span class="pl-s1">target</span>) <span class="pl-c1">in</span> <span class="pl-en">enumerate</span>(<span class="pl-s1">train_loader</span>):
    ...
    <span class="pl-k">if</span> <span class="pl-s1">batch_idx</span> <span class="pl-c1">%</span> <span class="pl-s1">args</span>.<span class="pl-s1">log_interval</span> <span class="pl-c1">==</span> <span class="pl-c1">0</span>:
        <span class="pl-c"># 4. Log metrics to visualize performance</span>
        <span class="pl-s1">run</span>.<span class="pl-en">log</span>({<span class="pl-s">"loss"</span>: <span class="pl-s1">loss</span>})</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="import wandb

# 1. Start a new run
run = wandb.init(project=&quot;gpt4&quot;)

# 2. Save model inputs and hyperparameters
config = run.config
config.dropout = 0.01

# 3. Log gradients and model parameters
run.watch(model)
for batch_idx, (data, target) in enumerate(train_loader):
    ...
    if batch_idx % args.log_interval == 0:
        # 4. Log metrics to visualize performance
        run.log({&quot;loss&quot;: loss})" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<ul dir="auto">
<li _msttexthash="18554107" _msthash="357">运行示例 <a href="http://wandb.me/pytorch-colab" rel="nofollow" _istranslated="1">Google Colab Notebook</a>。</li>
<li _msttexthash="214787157" _msthash="358">阅读<a href="https://docs.wandb.com/guides/integrations/pytorch?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">开发人员指南</a>以获取有关如何将 PyTorch 与 W&amp;B 集成的技术详细信息。</li>
<li _msttexthash="15500069" _msthash="359">探索 <a href="https://app.wandb.ai/wandb/getting-started/reports/Pytorch--VmlldzoyMTEwNzM?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">W&amp;B 报告</a>。</li>
</ul>
</details>
<details>
<summary _msttexthash="11316383" _msthash="360">🌊 TensorFlow/Keras</summary><font _mstmutation="1" _msttexthash="218751988" _msthash="361">当您在训练期间调用 'model.fit' 时，使用 W&amp;B Callbacks 自动将指标保存到 W&amp;B。</font><p dir="auto" _msttexthash="162379399" _msthash="362">以下代码示例演示了将 W&amp;B 与 Keras 集成时脚本的外观：</p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"># This script needs these libraries to be installed:</span>
<span class="pl-c">#   tensorflow, numpy</span>

<span class="pl-k">import</span> <span class="pl-s1">wandb</span>
<span class="pl-k">from</span> <span class="pl-s1">wandb</span>.<span class="pl-s1">keras</span> <span class="pl-k">import</span> <span class="pl-v">WandbMetricsLogger</span>, <span class="pl-v">WandbModelCheckpoint</span>

<span class="pl-k">import</span> <span class="pl-s1">random</span>
<span class="pl-k">import</span> <span class="pl-s1">numpy</span> <span class="pl-k">as</span> <span class="pl-s1">np</span>
<span class="pl-k">import</span> <span class="pl-s1">tensorflow</span> <span class="pl-k">as</span> <span class="pl-s1">tf</span>


<span class="pl-c"># Start a run, tracking hyperparameters</span>
<span class="pl-s1">run</span> <span class="pl-c1">=</span> <span class="pl-s1">wandb</span>.<span class="pl-en">init</span>(
    <span class="pl-c"># set the wandb project where this run will be logged</span>
    <span class="pl-s1">project</span><span class="pl-c1">=</span><span class="pl-s">"my-awesome-project"</span>,
    <span class="pl-c"># track hyperparameters and run metadata with wandb.config</span>
    <span class="pl-s1">config</span><span class="pl-c1">=</span>{
        <span class="pl-s">"layer_1"</span>: <span class="pl-c1">512</span>,
        <span class="pl-s">"activation_1"</span>: <span class="pl-s">"relu"</span>,
        <span class="pl-s">"dropout"</span>: <span class="pl-s1">random</span>.<span class="pl-en">uniform</span>(<span class="pl-c1">0.01</span>, <span class="pl-c1">0.80</span>),
        <span class="pl-s">"layer_2"</span>: <span class="pl-c1">10</span>,
        <span class="pl-s">"activation_2"</span>: <span class="pl-s">"softmax"</span>,
        <span class="pl-s">"optimizer"</span>: <span class="pl-s">"sgd"</span>,
        <span class="pl-s">"loss"</span>: <span class="pl-s">"sparse_categorical_crossentropy"</span>,
        <span class="pl-s">"metric"</span>: <span class="pl-s">"accuracy"</span>,
        <span class="pl-s">"epoch"</span>: <span class="pl-c1">8</span>,
        <span class="pl-s">"batch_size"</span>: <span class="pl-c1">256</span>,
    },
)

<span class="pl-c"># [optional] use wandb.config as your config</span>
<span class="pl-s1">config</span> <span class="pl-c1">=</span> <span class="pl-s1">run</span>.<span class="pl-s1">config</span>

<span class="pl-c"># get the data</span>
<span class="pl-s1">mnist</span> <span class="pl-c1">=</span> <span class="pl-s1">tf</span>.<span class="pl-s1">keras</span>.<span class="pl-s1">datasets</span>.<span class="pl-s1">mnist</span>
(<span class="pl-s1">x_train</span>, <span class="pl-s1">y_train</span>), (<span class="pl-s1">x_test</span>, <span class="pl-s1">y_test</span>) <span class="pl-c1">=</span> <span class="pl-s1">mnist</span>.<span class="pl-en">load_data</span>()
<span class="pl-s1">x_train</span>, <span class="pl-s1">x_test</span> <span class="pl-c1">=</span> <span class="pl-s1">x_train</span> <span class="pl-c1">/</span> <span class="pl-c1">255.0</span>, <span class="pl-s1">x_test</span> <span class="pl-c1">/</span> <span class="pl-c1">255.0</span>
<span class="pl-s1">x_train</span>, <span class="pl-s1">y_train</span> <span class="pl-c1">=</span> <span class="pl-s1">x_train</span>[::<span class="pl-c1">5</span>], <span class="pl-s1">y_train</span>[::<span class="pl-c1">5</span>]
<span class="pl-s1">x_test</span>, <span class="pl-s1">y_test</span> <span class="pl-c1">=</span> <span class="pl-s1">x_test</span>[::<span class="pl-c1">20</span>], <span class="pl-s1">y_test</span>[::<span class="pl-c1">20</span>]
<span class="pl-s1">labels</span> <span class="pl-c1">=</span> [<span class="pl-en">str</span>(<span class="pl-s1">digit</span>) <span class="pl-k">for</span> <span class="pl-s1">digit</span> <span class="pl-c1">in</span> <span class="pl-en">range</span>(<span class="pl-s1">np</span>.<span class="pl-en">max</span>(<span class="pl-s1">y_train</span>) <span class="pl-c1">+</span> <span class="pl-c1">1</span>)]

<span class="pl-c"># build a model</span>
<span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-s1">tf</span>.<span class="pl-s1">keras</span>.<span class="pl-s1">models</span>.<span class="pl-v">Sequential</span>(
    [
        <span class="pl-s1">tf</span>.<span class="pl-s1">keras</span>.<span class="pl-s1">layers</span>.<span class="pl-v">Flatten</span>(<span class="pl-s1">input_shape</span><span class="pl-c1">=</span>(<span class="pl-c1">28</span>, <span class="pl-c1">28</span>)),
        <span class="pl-s1">tf</span>.<span class="pl-s1">keras</span>.<span class="pl-s1">layers</span>.<span class="pl-v">Dense</span>(<span class="pl-s1">config</span>.<span class="pl-s1">layer_1</span>, <span class="pl-s1">activation</span><span class="pl-c1">=</span><span class="pl-s1">config</span>.<span class="pl-s1">activation_1</span>),
        <span class="pl-s1">tf</span>.<span class="pl-s1">keras</span>.<span class="pl-s1">layers</span>.<span class="pl-v">Dropout</span>(<span class="pl-s1">config</span>.<span class="pl-s1">dropout</span>),
        <span class="pl-s1">tf</span>.<span class="pl-s1">keras</span>.<span class="pl-s1">layers</span>.<span class="pl-v">Dense</span>(<span class="pl-s1">config</span>.<span class="pl-s1">layer_2</span>, <span class="pl-s1">activation</span><span class="pl-c1">=</span><span class="pl-s1">config</span>.<span class="pl-s1">activation_2</span>),
    ]
)

<span class="pl-c"># compile the model</span>
<span class="pl-s1">model</span>.<span class="pl-en">compile</span>(<span class="pl-s1">optimizer</span><span class="pl-c1">=</span><span class="pl-s1">config</span>.<span class="pl-s1">optimizer</span>, <span class="pl-s1">loss</span><span class="pl-c1">=</span><span class="pl-s1">config</span>.<span class="pl-s1">loss</span>, <span class="pl-s1">metrics</span><span class="pl-c1">=</span>[<span class="pl-s1">config</span>.<span class="pl-s1">metric</span>])

<span class="pl-c"># WandbMetricsLogger will log train and validation metrics to wandb</span>
<span class="pl-c"># WandbModelCheckpoint will upload model checkpoints to wandb</span>
<span class="pl-s1">history</span> <span class="pl-c1">=</span> <span class="pl-s1">model</span>.<span class="pl-en">fit</span>(
    <span class="pl-s1">x</span><span class="pl-c1">=</span><span class="pl-s1">x_train</span>,
    <span class="pl-s1">y</span><span class="pl-c1">=</span><span class="pl-s1">y_train</span>,
    <span class="pl-s1">epochs</span><span class="pl-c1">=</span><span class="pl-s1">config</span>.<span class="pl-s1">epoch</span>,
    <span class="pl-s1">batch_size</span><span class="pl-c1">=</span><span class="pl-s1">config</span>.<span class="pl-s1">batch_size</span>,
    <span class="pl-s1">validation_data</span><span class="pl-c1">=</span>(<span class="pl-s1">x_test</span>, <span class="pl-s1">y_test</span>),
    <span class="pl-s1">callbacks</span><span class="pl-c1">=</span>[
        <span class="pl-v">WandbMetricsLogger</span>(<span class="pl-s1">log_freq</span><span class="pl-c1">=</span><span class="pl-c1">5</span>),
        <span class="pl-v">WandbModelCheckpoint</span>(<span class="pl-s">"models"</span>),
    ],
)

<span class="pl-c"># [optional] finish the wandb run, necessary in notebooks</span>
<span class="pl-s1">run</span>.<span class="pl-en">finish</span>()</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# This script needs these libraries to be installed:
#   tensorflow, numpy

import wandb
from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint

import random
import numpy as np
import tensorflow as tf


# Start a run, tracking hyperparameters
run = wandb.init(
    # set the wandb project where this run will be logged
    project=&quot;my-awesome-project&quot;,
    # track hyperparameters and run metadata with wandb.config
    config={
        &quot;layer_1&quot;: 512,
        &quot;activation_1&quot;: &quot;relu&quot;,
        &quot;dropout&quot;: random.uniform(0.01, 0.80),
        &quot;layer_2&quot;: 10,
        &quot;activation_2&quot;: &quot;softmax&quot;,
        &quot;optimizer&quot;: &quot;sgd&quot;,
        &quot;loss&quot;: &quot;sparse_categorical_crossentropy&quot;,
        &quot;metric&quot;: &quot;accuracy&quot;,
        &quot;epoch&quot;: 8,
        &quot;batch_size&quot;: 256,
    },
)

# [optional] use wandb.config as your config
config = run.config

# get the data
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
x_train, y_train = x_train[::5], y_train[::5]
x_test, y_test = x_test[::20], y_test[::20]
labels = [str(digit) for digit in range(np.max(y_train) + 1)]

# build a model
model = tf.keras.models.Sequential(
    [
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(config.layer_1, activation=config.activation_1),
        tf.keras.layers.Dropout(config.dropout),
        tf.keras.layers.Dense(config.layer_2, activation=config.activation_2),
    ]
)

# compile the model
model.compile(optimizer=config.optimizer, loss=config.loss, metrics=[config.metric])

# WandbMetricsLogger will log train and validation metrics to wandb
# WandbModelCheckpoint will upload model checkpoints to wandb
history = model.fit(
    x=x_train,
    y=y_train,
    epochs=config.epoch,
    batch_size=config.batch_size,
    validation_data=(x_test, y_test),
    callbacks=[
        WandbMetricsLogger(log_freq=5),
        WandbModelCheckpoint(&quot;models&quot;),
    ],
)

# [optional] finish the wandb run, necessary in notebooks
run.finish()" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<p dir="auto" _msttexthash="85379242" _msthash="363">立即开始将您的 Keras 模型与 W&amp;B 集成：</p>
<ul dir="auto">
<li _msttexthash="13761007" _msthash="364">运行示例 <a href="https://wandb.me/intro-keras?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">Google Colab Notebook</a></li>
<li _msttexthash="216148673" _msthash="365">阅读<a href="https://docs.wandb.com/guides/integrations/keras?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">开发人员指南</a>，了解有关如何将 Keras 与 W&amp;B 集成的技术详细信息。</li>
<li _msttexthash="15500069" _msthash="366">探索 <a href="https://app.wandb.ai/wandb/getting-started/reports/Keras--VmlldzoyMTEwNjQ?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">W&amp;B 报告</a>。</li>
</ul>
</details>
<details>
<summary _msttexthash="28865876" _msthash="367">🤗 Hugging Face 变压器</summary>
<p dir="auto"><font _mstmutation="1" _msttexthash="508856322" _msthash="368">在使用 Hugging Face Trainer 运行脚本时传递给参数。W&amp;B将自动记录损失，
评估指标、模型拓扑和梯度。</font><code>wandb</code><code>report_to</code></p>
<p dir="auto"><font _mstmutation="1" _msttexthash="95880083" _msthash="369"><strong _mstmutation="1" _istranslated="1">注意</strong>：您运行脚本的环境必须已安装。</font><code>wandb</code></p>
<p dir="auto" _msttexthash="96825716" _msthash="370">以下示例演示了如何将 W&amp;B 与 Hugging Face 集成：</p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"># This script needs these libraries to be installed:</span>
<span class="pl-c">#   numpy, transformers, datasets</span>

<span class="pl-k">import</span> <span class="pl-s1">wandb</span>

<span class="pl-k">import</span> <span class="pl-s1">os</span>
<span class="pl-k">import</span> <span class="pl-s1">numpy</span> <span class="pl-k">as</span> <span class="pl-s1">np</span>
<span class="pl-k">from</span> <span class="pl-s1">datasets</span> <span class="pl-k">import</span> <span class="pl-s1">load_dataset</span>
<span class="pl-k">from</span> <span class="pl-s1">transformers</span> <span class="pl-k">import</span> <span class="pl-v">TrainingArguments</span>, <span class="pl-v">Trainer</span>
<span class="pl-k">from</span> <span class="pl-s1">transformers</span> <span class="pl-k">import</span> <span class="pl-v">AutoTokenizer</span>, <span class="pl-v">AutoModelForSequenceClassification</span>


<span class="pl-k">def</span> <span class="pl-en">tokenize_function</span>(<span class="pl-s1">examples</span>):
    <span class="pl-k">return</span> <span class="pl-en">tokenizer</span>(<span class="pl-s1">examples</span>[<span class="pl-s">"text"</span>], <span class="pl-s1">padding</span><span class="pl-c1">=</span><span class="pl-s">"max_length"</span>, <span class="pl-s1">truncation</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)


<span class="pl-k">def</span> <span class="pl-en">compute_metrics</span>(<span class="pl-s1">eval_pred</span>):
    <span class="pl-s1">logits</span>, <span class="pl-s1">labels</span> <span class="pl-c1">=</span> <span class="pl-s1">eval_pred</span>
    <span class="pl-s1">predictions</span> <span class="pl-c1">=</span> <span class="pl-s1">np</span>.<span class="pl-en">argmax</span>(<span class="pl-s1">logits</span>, <span class="pl-s1">axis</span><span class="pl-c1">=</span><span class="pl-c1">-</span><span class="pl-c1">1</span>)
    <span class="pl-k">return</span> {<span class="pl-s">"accuracy"</span>: <span class="pl-s1">np</span>.<span class="pl-en">mean</span>(<span class="pl-s1">predictions</span> <span class="pl-c1">==</span> <span class="pl-s1">labels</span>)}


<span class="pl-c"># download prepare the data</span>
<span class="pl-s1">dataset</span> <span class="pl-c1">=</span> <span class="pl-en">load_dataset</span>(<span class="pl-s">"yelp_review_full"</span>)
<span class="pl-s1">tokenizer</span> <span class="pl-c1">=</span> <span class="pl-v">AutoTokenizer</span>.<span class="pl-en">from_pretrained</span>(<span class="pl-s">"distilbert-base-uncased"</span>)

<span class="pl-s1">small_train_dataset</span> <span class="pl-c1">=</span> <span class="pl-s1">dataset</span>[<span class="pl-s">"train"</span>].<span class="pl-en">shuffle</span>(<span class="pl-s1">seed</span><span class="pl-c1">=</span><span class="pl-c1">42</span>).<span class="pl-en">select</span>(<span class="pl-en">range</span>(<span class="pl-c1">1000</span>))
<span class="pl-s1">small_eval_dataset</span> <span class="pl-c1">=</span> <span class="pl-s1">dataset</span>[<span class="pl-s">"test"</span>].<span class="pl-en">shuffle</span>(<span class="pl-s1">seed</span><span class="pl-c1">=</span><span class="pl-c1">42</span>).<span class="pl-en">select</span>(<span class="pl-en">range</span>(<span class="pl-c1">300</span>))

<span class="pl-s1">small_train_dataset</span> <span class="pl-c1">=</span> <span class="pl-s1">small_train_dataset</span>.<span class="pl-en">map</span>(<span class="pl-s1">tokenize_function</span>, <span class="pl-s1">batched</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)
<span class="pl-s1">small_eval_dataset</span> <span class="pl-c1">=</span> <span class="pl-s1">small_train_dataset</span>.<span class="pl-en">map</span>(<span class="pl-s1">tokenize_function</span>, <span class="pl-s1">batched</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)

<span class="pl-c"># download the model</span>
<span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-v">AutoModelForSequenceClassification</span>.<span class="pl-en">from_pretrained</span>(
    <span class="pl-s">"distilbert-base-uncased"</span>, <span class="pl-s1">num_labels</span><span class="pl-c1">=</span><span class="pl-c1">5</span>
)

<span class="pl-c"># set the wandb project where this run will be logged</span>
<span class="pl-s1">os</span>.<span class="pl-s1">environ</span>[<span class="pl-s">"WANDB_PROJECT"</span>] <span class="pl-c1">=</span> <span class="pl-s">"my-awesome-project"</span>

<span class="pl-c"># save your trained model checkpoint to wandb</span>
<span class="pl-s1">os</span>.<span class="pl-s1">environ</span>[<span class="pl-s">"WANDB_LOG_MODEL"</span>] <span class="pl-c1">=</span> <span class="pl-s">"true"</span>

<span class="pl-c"># turn off watch to log faster</span>
<span class="pl-s1">os</span>.<span class="pl-s1">environ</span>[<span class="pl-s">"WANDB_WATCH"</span>] <span class="pl-c1">=</span> <span class="pl-s">"false"</span>

<span class="pl-c"># pass "wandb" to the `report_to` parameter to turn on wandb logging</span>
<span class="pl-s1">training_args</span> <span class="pl-c1">=</span> <span class="pl-v">TrainingArguments</span>(
    <span class="pl-s1">output_dir</span><span class="pl-c1">=</span><span class="pl-s">"models"</span>,
    <span class="pl-s1">report_to</span><span class="pl-c1">=</span><span class="pl-s">"wandb"</span>,
    <span class="pl-s1">logging_steps</span><span class="pl-c1">=</span><span class="pl-c1">5</span>,
    <span class="pl-s1">per_device_train_batch_size</span><span class="pl-c1">=</span><span class="pl-c1">32</span>,
    <span class="pl-s1">per_device_eval_batch_size</span><span class="pl-c1">=</span><span class="pl-c1">32</span>,
    <span class="pl-s1">evaluation_strategy</span><span class="pl-c1">=</span><span class="pl-s">"steps"</span>,
    <span class="pl-s1">eval_steps</span><span class="pl-c1">=</span><span class="pl-c1">20</span>,
    <span class="pl-s1">max_steps</span><span class="pl-c1">=</span><span class="pl-c1">100</span>,
    <span class="pl-s1">save_steps</span><span class="pl-c1">=</span><span class="pl-c1">100</span>,
)

<span class="pl-c"># define the trainer and start training</span>
<span class="pl-s1">trainer</span> <span class="pl-c1">=</span> <span class="pl-v">Trainer</span>(
    <span class="pl-s1">model</span><span class="pl-c1">=</span><span class="pl-s1">model</span>,
    <span class="pl-s1">args</span><span class="pl-c1">=</span><span class="pl-s1">training_args</span>,
    <span class="pl-s1">train_dataset</span><span class="pl-c1">=</span><span class="pl-s1">small_train_dataset</span>,
    <span class="pl-s1">eval_dataset</span><span class="pl-c1">=</span><span class="pl-s1">small_eval_dataset</span>,
    <span class="pl-s1">compute_metrics</span><span class="pl-c1">=</span><span class="pl-s1">compute_metrics</span>,
)
<span class="pl-s1">trainer</span>.<span class="pl-en">train</span>()

<span class="pl-c"># [optional] finish the wandb run, necessary in notebooks</span>
<span class="pl-s1">wandb</span>.<span class="pl-en">finish</span>()</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# This script needs these libraries to be installed:
#   numpy, transformers, datasets

import wandb

import os
import numpy as np
from datasets import load_dataset
from transformers import TrainingArguments, Trainer
from transformers import AutoTokenizer, AutoModelForSequenceClassification


def tokenize_function(examples):
    return tokenizer(examples[&quot;text&quot;], padding=&quot;max_length&quot;, truncation=True)


def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return {&quot;accuracy&quot;: np.mean(predictions == labels)}


# download prepare the data
dataset = load_dataset(&quot;yelp_review_full&quot;)
tokenizer = AutoTokenizer.from_pretrained(&quot;distilbert-base-uncased&quot;)

small_train_dataset = dataset[&quot;train&quot;].shuffle(seed=42).select(range(1000))
small_eval_dataset = dataset[&quot;test&quot;].shuffle(seed=42).select(range(300))

small_train_dataset = small_train_dataset.map(tokenize_function, batched=True)
small_eval_dataset = small_train_dataset.map(tokenize_function, batched=True)

# download the model
model = AutoModelForSequenceClassification.from_pretrained(
    &quot;distilbert-base-uncased&quot;, num_labels=5
)

# set the wandb project where this run will be logged
os.environ[&quot;WANDB_PROJECT&quot;] = &quot;my-awesome-project&quot;

# save your trained model checkpoint to wandb
os.environ[&quot;WANDB_LOG_MODEL&quot;] = &quot;true&quot;

# turn off watch to log faster
os.environ[&quot;WANDB_WATCH&quot;] = &quot;false&quot;

# pass &quot;wandb&quot; to the `report_to` parameter to turn on wandb logging
training_args = TrainingArguments(
    output_dir=&quot;models&quot;,
    report_to=&quot;wandb&quot;,
    logging_steps=5,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    evaluation_strategy=&quot;steps&quot;,
    eval_steps=20,
    max_steps=100,
    save_steps=100,
)

# define the trainer and start training
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)
trainer.train()

# [optional] finish the wandb run, necessary in notebooks
wandb.finish()" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<ul dir="auto">
<li _msttexthash="18554107" _msthash="371">运行示例 <a href="http://wandb.me/hf?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">Google Colab Notebook</a>。</li>
<li _msttexthash="175086340" _msthash="372">阅读<a href="https://docs.wandb.com/guides/integrations/huggingface?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">开发者指南</a>以获取如何将Hugging Face与W&amp;B集成的技术细节。</li>
</ul>
</details>
<details>
<summary _msttexthash="22389666" _msthash="373">⚡️ PyTorch 闪电</summary>
<p dir="auto" _msttexthash="296488959" _msthash="374">使用 Lightning 构建可扩展、结构化、高性能的 PyTorch 模型，并使用 W&amp;B 记录它们。</p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"># This script needs these libraries to be installed:</span>
<span class="pl-c">#   torch, torchvision, pytorch_lightning</span>

<span class="pl-k">import</span> <span class="pl-s1">wandb</span>

<span class="pl-k">import</span> <span class="pl-s1">os</span>
<span class="pl-k">from</span> <span class="pl-s1">torch</span> <span class="pl-k">import</span> <span class="pl-s1">optim</span>, <span class="pl-s1">nn</span>, <span class="pl-s1">utils</span>
<span class="pl-k">from</span> <span class="pl-s1">torchvision</span>.<span class="pl-s1">datasets</span> <span class="pl-k">import</span> <span class="pl-v">MNIST</span>
<span class="pl-k">from</span> <span class="pl-s1">torchvision</span>.<span class="pl-s1">transforms</span> <span class="pl-k">import</span> <span class="pl-v">ToTensor</span>

<span class="pl-k">import</span> <span class="pl-s1">pytorch_lightning</span> <span class="pl-k">as</span> <span class="pl-s1">pl</span>
<span class="pl-k">from</span> <span class="pl-s1">pytorch_lightning</span>.<span class="pl-s1">loggers</span> <span class="pl-k">import</span> <span class="pl-v">WandbLogger</span>


<span class="pl-k">class</span> <span class="pl-v">LitAutoEncoder</span>(<span class="pl-s1">pl</span>.<span class="pl-v">LightningModule</span>):
    <span class="pl-k">def</span> <span class="pl-en">__init__</span>(<span class="pl-s1">self</span>, <span class="pl-s1">lr</span><span class="pl-c1">=</span><span class="pl-c1">1e-3</span>, <span class="pl-s1">inp_size</span><span class="pl-c1">=</span><span class="pl-c1">28</span>, <span class="pl-s1">optimizer</span><span class="pl-c1">=</span><span class="pl-s">"Adam"</span>):
        <span class="pl-en">super</span>().<span class="pl-en">__init__</span>()

        <span class="pl-s1">self</span>.<span class="pl-s1">encoder</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">Sequential</span>(
            <span class="pl-s1">nn</span>.<span class="pl-v">Linear</span>(<span class="pl-s1">inp_size</span> <span class="pl-c1">*</span> <span class="pl-s1">inp_size</span>, <span class="pl-c1">64</span>), <span class="pl-s1">nn</span>.<span class="pl-v">ReLU</span>(), <span class="pl-s1">nn</span>.<span class="pl-v">Linear</span>(<span class="pl-c1">64</span>, <span class="pl-c1">3</span>)
        )
        <span class="pl-s1">self</span>.<span class="pl-s1">decoder</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-v">Sequential</span>(
            <span class="pl-s1">nn</span>.<span class="pl-v">Linear</span>(<span class="pl-c1">3</span>, <span class="pl-c1">64</span>), <span class="pl-s1">nn</span>.<span class="pl-v">ReLU</span>(), <span class="pl-s1">nn</span>.<span class="pl-v">Linear</span>(<span class="pl-c1">64</span>, <span class="pl-s1">inp_size</span> <span class="pl-c1">*</span> <span class="pl-s1">inp_size</span>)
        )
        <span class="pl-s1">self</span>.<span class="pl-s1">lr</span> <span class="pl-c1">=</span> <span class="pl-s1">lr</span>

        <span class="pl-c"># save hyperparameters to self.hparamsm auto-logged by wandb</span>
        <span class="pl-s1">self</span>.<span class="pl-en">save_hyperparameters</span>()

    <span class="pl-k">def</span> <span class="pl-en">training_step</span>(<span class="pl-s1">self</span>, <span class="pl-s1">batch</span>, <span class="pl-s1">batch_idx</span>):
        <span class="pl-s1">x</span>, <span class="pl-s1">y</span> <span class="pl-c1">=</span> <span class="pl-s1">batch</span>
        <span class="pl-s1">x</span> <span class="pl-c1">=</span> <span class="pl-s1">x</span>.<span class="pl-en">view</span>(<span class="pl-s1">x</span>.<span class="pl-en">size</span>(<span class="pl-c1">0</span>), <span class="pl-c1">-</span><span class="pl-c1">1</span>)
        <span class="pl-s1">z</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">encoder</span>(<span class="pl-s1">x</span>)
        <span class="pl-s1">x_hat</span> <span class="pl-c1">=</span> <span class="pl-s1">self</span>.<span class="pl-en">decoder</span>(<span class="pl-s1">z</span>)
        <span class="pl-s1">loss</span> <span class="pl-c1">=</span> <span class="pl-s1">nn</span>.<span class="pl-s1">functional</span>.<span class="pl-en">mse_loss</span>(<span class="pl-s1">x_hat</span>, <span class="pl-s1">x</span>)

        <span class="pl-c"># log metrics to wandb</span>
        <span class="pl-s1">self</span>.<span class="pl-en">log</span>(<span class="pl-s">"train_loss"</span>, <span class="pl-s1">loss</span>)
        <span class="pl-k">return</span> <span class="pl-s1">loss</span>

    <span class="pl-k">def</span> <span class="pl-en">configure_optimizers</span>(<span class="pl-s1">self</span>):
        <span class="pl-s1">optimizer</span> <span class="pl-c1">=</span> <span class="pl-s1">optim</span>.<span class="pl-v">Adam</span>(<span class="pl-s1">self</span>.<span class="pl-en">parameters</span>(), <span class="pl-s1">lr</span><span class="pl-c1">=</span><span class="pl-s1">self</span>.<span class="pl-s1">lr</span>)
        <span class="pl-k">return</span> <span class="pl-s1">optimizer</span>


<span class="pl-c"># init the autoencoder</span>
<span class="pl-s1">autoencoder</span> <span class="pl-c1">=</span> <span class="pl-v">LitAutoEncoder</span>(<span class="pl-s1">lr</span><span class="pl-c1">=</span><span class="pl-c1">1e-3</span>, <span class="pl-s1">inp_size</span><span class="pl-c1">=</span><span class="pl-c1">28</span>)

<span class="pl-c"># setup data</span>
<span class="pl-s1">batch_size</span> <span class="pl-c1">=</span> <span class="pl-c1">32</span>
<span class="pl-s1">dataset</span> <span class="pl-c1">=</span> <span class="pl-v">MNIST</span>(<span class="pl-s1">os</span>.<span class="pl-en">getcwd</span>(), <span class="pl-s1">download</span><span class="pl-c1">=</span><span class="pl-c1">True</span>, <span class="pl-s1">transform</span><span class="pl-c1">=</span><span class="pl-v">ToTensor</span>())
<span class="pl-s1">train_loader</span> <span class="pl-c1">=</span> <span class="pl-s1">utils</span>.<span class="pl-s1">data</span>.<span class="pl-v">DataLoader</span>(<span class="pl-s1">dataset</span>, <span class="pl-s1">shuffle</span><span class="pl-c1">=</span><span class="pl-c1">True</span>)

<span class="pl-c"># initialise the wandb logger and name your wandb project</span>
<span class="pl-s1">wandb_logger</span> <span class="pl-c1">=</span> <span class="pl-v">WandbLogger</span>(<span class="pl-s1">project</span><span class="pl-c1">=</span><span class="pl-s">"my-awesome-project"</span>)

<span class="pl-c"># add your batch size to the wandb config</span>
<span class="pl-s1">wandb_logger</span>.<span class="pl-s1">experiment</span>.<span class="pl-s1">config</span>[<span class="pl-s">"batch_size"</span>] <span class="pl-c1">=</span> <span class="pl-s1">batch_size</span>

<span class="pl-c"># pass wandb_logger to the Trainer</span>
<span class="pl-s1">trainer</span> <span class="pl-c1">=</span> <span class="pl-s1">pl</span>.<span class="pl-v">Trainer</span>(<span class="pl-s1">limit_train_batches</span><span class="pl-c1">=</span><span class="pl-c1">750</span>, <span class="pl-s1">max_epochs</span><span class="pl-c1">=</span><span class="pl-c1">5</span>, <span class="pl-s1">logger</span><span class="pl-c1">=</span><span class="pl-s1">wandb_logger</span>)

<span class="pl-c"># train the model</span>
<span class="pl-s1">trainer</span>.<span class="pl-en">fit</span>(<span class="pl-s1">model</span><span class="pl-c1">=</span><span class="pl-s1">autoencoder</span>, <span class="pl-s1">train_dataloaders</span><span class="pl-c1">=</span><span class="pl-s1">train_loader</span>)

<span class="pl-c"># [optional] finish the wandb run, necessary in notebooks</span>
<span class="pl-s1">wandb</span>.<span class="pl-en">finish</span>()</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# This script needs these libraries to be installed:
#   torch, torchvision, pytorch_lightning

import wandb

import os
from torch import optim, nn, utils
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor

import pytorch_lightning as pl
from pytorch_lightning.loggers import WandbLogger


class LitAutoEncoder(pl.LightningModule):
    def __init__(self, lr=1e-3, inp_size=28, optimizer=&quot;Adam&quot;):
        super().__init__()

        self.encoder = nn.Sequential(
            nn.Linear(inp_size * inp_size, 64), nn.ReLU(), nn.Linear(64, 3)
        )
        self.decoder = nn.Sequential(
            nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, inp_size * inp_size)
        )
        self.lr = lr

        # save hyperparameters to self.hparamsm auto-logged by wandb
        self.save_hyperparameters()

    def training_step(self, batch, batch_idx):
        x, y = batch
        x = x.view(x.size(0), -1)
        z = self.encoder(x)
        x_hat = self.decoder(z)
        loss = nn.functional.mse_loss(x_hat, x)

        # log metrics to wandb
        self.log(&quot;train_loss&quot;, loss)
        return loss

    def configure_optimizers(self):
        optimizer = optim.Adam(self.parameters(), lr=self.lr)
        return optimizer


# init the autoencoder
autoencoder = LitAutoEncoder(lr=1e-3, inp_size=28)

# setup data
batch_size = 32
dataset = MNIST(os.getcwd(), download=True, transform=ToTensor())
train_loader = utils.data.DataLoader(dataset, shuffle=True)

# initialise the wandb logger and name your wandb project
wandb_logger = WandbLogger(project=&quot;my-awesome-project&quot;)

# add your batch size to the wandb config
wandb_logger.experiment.config[&quot;batch_size&quot;] = batch_size

# pass wandb_logger to the Trainer
trainer = pl.Trainer(limit_train_batches=750, max_epochs=5, logger=wandb_logger)

# train the model
trainer.fit(model=autoencoder, train_dataloaders=train_loader)

# [optional] finish the wandb run, necessary in notebooks
wandb.finish()" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<ul dir="auto">
<li _msttexthash="18554107" _msthash="375">运行示例 <a href="http://wandb.me/lightning?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">Google Colab Notebook</a>。</li>
<li _msttexthash="258330176" _msthash="376">阅读<a href="https://docs.wandb.ai/guides/integrations/lightning?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">开发人员指南</a>，了解有关如何将PyTorch Lightning与W&amp;B集成的技术详细信息。</li>
</ul>
</details>
<details>
<summary _msttexthash="11020828" _msthash="377">💨 XGBoost</summary><font _mstmutation="1" _msttexthash="218751988" _msthash="378">当您在训练期间调用 'model.fit' 时，使用 W&amp;B Callbacks 自动将指标保存到 W&amp;B。</font><p dir="auto" _msttexthash="170320254" _msthash="379">以下代码示例演示了将 W&amp;B 与 XGBoost 集成时脚本的外观：</p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"># This script needs these libraries to be installed:</span>
<span class="pl-c">#   numpy, xgboost</span>

<span class="pl-k">import</span> <span class="pl-s1">wandb</span>
<span class="pl-k">from</span> <span class="pl-s1">wandb</span>.<span class="pl-s1">xgboost</span> <span class="pl-k">import</span> <span class="pl-v">WandbCallback</span>

<span class="pl-k">import</span> <span class="pl-s1">numpy</span> <span class="pl-k">as</span> <span class="pl-s1">np</span>
<span class="pl-k">import</span> <span class="pl-s1">xgboost</span> <span class="pl-k">as</span> <span class="pl-s1">xgb</span>


<span class="pl-c"># setup parameters for xgboost</span>
<span class="pl-s1">param</span> <span class="pl-c1">=</span> {
    <span class="pl-s">"objective"</span>: <span class="pl-s">"multi:softmax"</span>,
    <span class="pl-s">"eta"</span>: <span class="pl-c1">0.1</span>,
    <span class="pl-s">"max_depth"</span>: <span class="pl-c1">6</span>,
    <span class="pl-s">"nthread"</span>: <span class="pl-c1">4</span>,
    <span class="pl-s">"num_class"</span>: <span class="pl-c1">6</span>,
}

<span class="pl-c"># start a new wandb run to track this script</span>
<span class="pl-s1">run</span> <span class="pl-c1">=</span> <span class="pl-s1">wandb</span>.<span class="pl-en">init</span>(
    <span class="pl-c"># set the wandb project where this run will be logged</span>
    <span class="pl-s1">project</span><span class="pl-c1">=</span><span class="pl-s">"my-awesome-project"</span>,
    <span class="pl-c"># track hyperparameters and run metadata</span>
    <span class="pl-s1">config</span><span class="pl-c1">=</span><span class="pl-s1">param</span>,
)

<span class="pl-c"># download data from wandb Artifacts and prep data</span>
<span class="pl-s1">run</span>.<span class="pl-en">use_artifact</span>(<span class="pl-s">"wandb/intro/dermatology_data:v0"</span>, <span class="pl-s1">type</span><span class="pl-c1">=</span><span class="pl-s">"dataset"</span>).<span class="pl-en">download</span>(<span class="pl-s">"."</span>)
<span class="pl-s1">data</span> <span class="pl-c1">=</span> <span class="pl-s1">np</span>.<span class="pl-en">loadtxt</span>(
    <span class="pl-s">"./dermatology.data"</span>,
    <span class="pl-s1">delimiter</span><span class="pl-c1">=</span><span class="pl-s">","</span>,
    <span class="pl-s1">converters</span><span class="pl-c1">=</span>{<span class="pl-c1">33</span>: <span class="pl-k">lambda</span> <span class="pl-s1">x</span>: <span class="pl-en">int</span>(<span class="pl-s1">x</span> <span class="pl-c1">==</span> <span class="pl-s">"?"</span>), <span class="pl-c1">34</span>: <span class="pl-k">lambda</span> <span class="pl-s1">x</span>: <span class="pl-en">int</span>(<span class="pl-s1">x</span>) <span class="pl-c1">-</span> <span class="pl-c1">1</span>},
)
<span class="pl-s1">sz</span> <span class="pl-c1">=</span> <span class="pl-s1">data</span>.<span class="pl-s1">shape</span>

<span class="pl-s1">train</span> <span class="pl-c1">=</span> <span class="pl-s1">data</span>[: <span class="pl-en">int</span>(<span class="pl-s1">sz</span>[<span class="pl-c1">0</span>] <span class="pl-c1">*</span> <span class="pl-c1">0.7</span>), :]
<span class="pl-s1">test</span> <span class="pl-c1">=</span> <span class="pl-s1">data</span>[<span class="pl-en">int</span>(<span class="pl-s1">sz</span>[<span class="pl-c1">0</span>] <span class="pl-c1">*</span> <span class="pl-c1">0.7</span>) :, :]

<span class="pl-s1">train_X</span> <span class="pl-c1">=</span> <span class="pl-s1">train</span>[:, :<span class="pl-c1">33</span>]
<span class="pl-s1">train_Y</span> <span class="pl-c1">=</span> <span class="pl-s1">train</span>[:, <span class="pl-c1">34</span>]

<span class="pl-s1">test_X</span> <span class="pl-c1">=</span> <span class="pl-s1">test</span>[:, :<span class="pl-c1">33</span>]
<span class="pl-s1">test_Y</span> <span class="pl-c1">=</span> <span class="pl-s1">test</span>[:, <span class="pl-c1">34</span>]

<span class="pl-s1">xg_train</span> <span class="pl-c1">=</span> <span class="pl-s1">xgb</span>.<span class="pl-v">DMatrix</span>(<span class="pl-s1">train_X</span>, <span class="pl-s1">label</span><span class="pl-c1">=</span><span class="pl-s1">train_Y</span>)
<span class="pl-s1">xg_test</span> <span class="pl-c1">=</span> <span class="pl-s1">xgb</span>.<span class="pl-v">DMatrix</span>(<span class="pl-s1">test_X</span>, <span class="pl-s1">label</span><span class="pl-c1">=</span><span class="pl-s1">test_Y</span>)
<span class="pl-s1">watchlist</span> <span class="pl-c1">=</span> [(<span class="pl-s1">xg_train</span>, <span class="pl-s">"train"</span>), (<span class="pl-s1">xg_test</span>, <span class="pl-s">"test"</span>)]

<span class="pl-c"># add another config to the wandb run</span>
<span class="pl-s1">num_round</span> <span class="pl-c1">=</span> <span class="pl-c1">5</span>
<span class="pl-s1">run</span>.<span class="pl-s1">config</span>[<span class="pl-s">"num_round"</span>] <span class="pl-c1">=</span> <span class="pl-c1">5</span>
<span class="pl-s1">run</span>.<span class="pl-s1">config</span>[<span class="pl-s">"data_shape"</span>] <span class="pl-c1">=</span> <span class="pl-s1">sz</span>

<span class="pl-c"># pass WandbCallback to the booster to log its configs and metrics</span>
<span class="pl-s1">bst</span> <span class="pl-c1">=</span> <span class="pl-s1">xgb</span>.<span class="pl-en">train</span>(
    <span class="pl-s1">param</span>, <span class="pl-s1">xg_train</span>, <span class="pl-s1">num_round</span>, <span class="pl-s1">evals</span><span class="pl-c1">=</span><span class="pl-s1">watchlist</span>, <span class="pl-s1">callbacks</span><span class="pl-c1">=</span>[<span class="pl-v">WandbCallback</span>()]
)

<span class="pl-c"># get prediction</span>
<span class="pl-s1">pred</span> <span class="pl-c1">=</span> <span class="pl-s1">bst</span>.<span class="pl-en">predict</span>(<span class="pl-s1">xg_test</span>)
<span class="pl-s1">error_rate</span> <span class="pl-c1">=</span> <span class="pl-s1">np</span>.<span class="pl-en">sum</span>(<span class="pl-s1">pred</span> <span class="pl-c1">!=</span> <span class="pl-s1">test_Y</span>) <span class="pl-c1">/</span> <span class="pl-s1">test_Y</span>.<span class="pl-s1">shape</span>[<span class="pl-c1">0</span>]

<span class="pl-c"># log your test metric to wandb</span>
<span class="pl-s1">run</span>.<span class="pl-s1">summary</span>[<span class="pl-s">"Error Rate"</span>] <span class="pl-c1">=</span> <span class="pl-s1">error_rate</span>

<span class="pl-c"># [optional] finish the wandb run, necessary in notebooks</span>
<span class="pl-s1">run</span>.<span class="pl-en">finish</span>()</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# This script needs these libraries to be installed:
#   numpy, xgboost

import wandb
from wandb.xgboost import WandbCallback

import numpy as np
import xgboost as xgb


# setup parameters for xgboost
param = {
    &quot;objective&quot;: &quot;multi:softmax&quot;,
    &quot;eta&quot;: 0.1,
    &quot;max_depth&quot;: 6,
    &quot;nthread&quot;: 4,
    &quot;num_class&quot;: 6,
}

# start a new wandb run to track this script
run = wandb.init(
    # set the wandb project where this run will be logged
    project=&quot;my-awesome-project&quot;,
    # track hyperparameters and run metadata
    config=param,
)

# download data from wandb Artifacts and prep data
run.use_artifact(&quot;wandb/intro/dermatology_data:v0&quot;, type=&quot;dataset&quot;).download(&quot;.&quot;)
data = np.loadtxt(
    &quot;./dermatology.data&quot;,
    delimiter=&quot;,&quot;,
    converters={33: lambda x: int(x == &quot;?&quot;), 34: lambda x: int(x) - 1},
)
sz = data.shape

train = data[: int(sz[0] * 0.7), :]
test = data[int(sz[0] * 0.7) :, :]

train_X = train[:, :33]
train_Y = train[:, 34]

test_X = test[:, :33]
test_Y = test[:, 34]

xg_train = xgb.DMatrix(train_X, label=train_Y)
xg_test = xgb.DMatrix(test_X, label=test_Y)
watchlist = [(xg_train, &quot;train&quot;), (xg_test, &quot;test&quot;)]

# add another config to the wandb run
num_round = 5
run.config[&quot;num_round&quot;] = 5
run.config[&quot;data_shape&quot;] = sz

# pass WandbCallback to the booster to log its configs and metrics
bst = xgb.train(
    param, xg_train, num_round, evals=watchlist, callbacks=[WandbCallback()]
)

# get prediction
pred = bst.predict(xg_test)
error_rate = np.sum(pred != test_Y) / test_Y.shape[0]

# log your test metric to wandb
run.summary[&quot;Error Rate&quot;] = error_rate

# [optional] finish the wandb run, necessary in notebooks
run.finish()" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<ul dir="auto">
<li _msttexthash="18554107" _msthash="380">运行示例 <a href="https://wandb.me/xgboost?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">Google Colab Notebook</a>。</li>
<li _msttexthash="206345776" _msthash="381">阅读<a href="https://docs.wandb.ai/guides/integrations/xgboost?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">开发者指南</a>以获取有关如何将XGBoost与W&amp;B集成的技术详细信息。</li>
</ul>
</details>
<details>
<summary _msttexthash="20346183" _msthash="382">🧮 Sci-Kit 学习</summary><font _mstmutation="1" _msttexthash="133372564" _msthash="383">使用 wandb 可视化和比较 scikit-learn 模型的性能：</font><div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"># This script needs these libraries to be installed:</span>
<span class="pl-c">#   numpy, sklearn</span>

<span class="pl-k">import</span> <span class="pl-s1">wandb</span>
<span class="pl-k">from</span> <span class="pl-s1">wandb</span>.<span class="pl-s1">sklearn</span> <span class="pl-k">import</span> <span class="pl-s1">plot_precision_recall</span>, <span class="pl-s1">plot_feature_importances</span>
<span class="pl-k">from</span> <span class="pl-s1">wandb</span>.<span class="pl-s1">sklearn</span> <span class="pl-k">import</span> <span class="pl-s1">plot_class_proportions</span>, <span class="pl-s1">plot_learning_curve</span>, <span class="pl-s1">plot_roc</span>

<span class="pl-k">import</span> <span class="pl-s1">numpy</span> <span class="pl-k">as</span> <span class="pl-s1">np</span>
<span class="pl-k">from</span> <span class="pl-s1">sklearn</span> <span class="pl-k">import</span> <span class="pl-s1">datasets</span>
<span class="pl-k">from</span> <span class="pl-s1">sklearn</span>.<span class="pl-s1">ensemble</span> <span class="pl-k">import</span> <span class="pl-v">RandomForestClassifier</span>
<span class="pl-k">from</span> <span class="pl-s1">sklearn</span>.<span class="pl-s1">model_selection</span> <span class="pl-k">import</span> <span class="pl-s1">train_test_split</span>


<span class="pl-c"># load and process data</span>
<span class="pl-s1">wbcd</span> <span class="pl-c1">=</span> <span class="pl-s1">datasets</span>.<span class="pl-en">load_breast_cancer</span>()
<span class="pl-s1">feature_names</span> <span class="pl-c1">=</span> <span class="pl-s1">wbcd</span>.<span class="pl-s1">feature_names</span>
<span class="pl-s1">labels</span> <span class="pl-c1">=</span> <span class="pl-s1">wbcd</span>.<span class="pl-s1">target_names</span>

<span class="pl-s1">test_size</span> <span class="pl-c1">=</span> <span class="pl-c1">0.2</span>
<span class="pl-v">X_train</span>, <span class="pl-v">X_test</span>, <span class="pl-s1">y_train</span>, <span class="pl-s1">y_test</span> <span class="pl-c1">=</span> <span class="pl-en">train_test_split</span>(
    <span class="pl-s1">wbcd</span>.<span class="pl-s1">data</span>, <span class="pl-s1">wbcd</span>.<span class="pl-s1">target</span>, <span class="pl-s1">test_size</span><span class="pl-c1">=</span><span class="pl-s1">test_size</span>
)

<span class="pl-c"># train model</span>
<span class="pl-s1">model</span> <span class="pl-c1">=</span> <span class="pl-v">RandomForestClassifier</span>()
<span class="pl-s1">model</span>.<span class="pl-en">fit</span>(<span class="pl-v">X_train</span>, <span class="pl-s1">y_train</span>)
<span class="pl-s1">model_params</span> <span class="pl-c1">=</span> <span class="pl-s1">model</span>.<span class="pl-en">get_params</span>()

<span class="pl-c"># get predictions</span>
<span class="pl-s1">y_pred</span> <span class="pl-c1">=</span> <span class="pl-s1">model</span>.<span class="pl-en">predict</span>(<span class="pl-v">X_test</span>)
<span class="pl-s1">y_probas</span> <span class="pl-c1">=</span> <span class="pl-s1">model</span>.<span class="pl-en">predict_proba</span>(<span class="pl-v">X_test</span>)
<span class="pl-s1">importances</span> <span class="pl-c1">=</span> <span class="pl-s1">model</span>.<span class="pl-s1">feature_importances_</span>
<span class="pl-s1">indices</span> <span class="pl-c1">=</span> <span class="pl-s1">np</span>.<span class="pl-en">argsort</span>(<span class="pl-s1">importances</span>)[::<span class="pl-c1">-</span><span class="pl-c1">1</span>]

<span class="pl-c"># start a new wandb run and add your model hyperparameters</span>
<span class="pl-s1">run</span> <span class="pl-c1">=</span> <span class="pl-s1">wandb</span>.<span class="pl-en">init</span>(<span class="pl-s1">project</span><span class="pl-c1">=</span><span class="pl-s">"my-awesome-project"</span>, <span class="pl-s1">config</span><span class="pl-c1">=</span><span class="pl-s1">model_params</span>)

<span class="pl-c"># Add additional configs to wandb</span>
<span class="pl-s1">run</span>.<span class="pl-s1">config</span>.<span class="pl-en">update</span>(
    {
        <span class="pl-s">"test_size"</span>: <span class="pl-s1">test_size</span>,
        <span class="pl-s">"train_len"</span>: <span class="pl-en">len</span>(<span class="pl-v">X_train</span>),
        <span class="pl-s">"test_len"</span>: <span class="pl-en">len</span>(<span class="pl-v">X_test</span>),
    }
)

<span class="pl-c"># log additional visualisations to wandb</span>
<span class="pl-en">plot_class_proportions</span>(<span class="pl-s1">y_train</span>, <span class="pl-s1">y_test</span>, <span class="pl-s1">labels</span>)
<span class="pl-en">plot_learning_curve</span>(<span class="pl-s1">model</span>, <span class="pl-v">X_train</span>, <span class="pl-s1">y_train</span>)
<span class="pl-en">plot_roc</span>(<span class="pl-s1">y_test</span>, <span class="pl-s1">y_probas</span>, <span class="pl-s1">labels</span>)
<span class="pl-en">plot_precision_recall</span>(<span class="pl-s1">y_test</span>, <span class="pl-s1">y_probas</span>, <span class="pl-s1">labels</span>)
<span class="pl-en">plot_feature_importances</span>(<span class="pl-s1">model</span>)

<span class="pl-c"># [optional] finish the wandb run, necessary in notebooks</span>
<span class="pl-s1">run</span>.<span class="pl-en">finish</span>()</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# This script needs these libraries to be installed:
#   numpy, sklearn

import wandb
from wandb.sklearn import plot_precision_recall, plot_feature_importances
from wandb.sklearn import plot_class_proportions, plot_learning_curve, plot_roc

import numpy as np
from sklearn import datasets
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split


# load and process data
wbcd = datasets.load_breast_cancer()
feature_names = wbcd.feature_names
labels = wbcd.target_names

test_size = 0.2
X_train, X_test, y_train, y_test = train_test_split(
    wbcd.data, wbcd.target, test_size=test_size
)

# train model
model = RandomForestClassifier()
model.fit(X_train, y_train)
model_params = model.get_params()

# get predictions
y_pred = model.predict(X_test)
y_probas = model.predict_proba(X_test)
importances = model.feature_importances_
indices = np.argsort(importances)[::-1]

# start a new wandb run and add your model hyperparameters
run = wandb.init(project=&quot;my-awesome-project&quot;, config=model_params)

# Add additional configs to wandb
run.config.update(
    {
        &quot;test_size&quot;: test_size,
        &quot;train_len&quot;: len(X_train),
        &quot;test_len&quot;: len(X_test),
    }
)

# log additional visualisations to wandb
plot_class_proportions(y_train, y_test, labels)
plot_learning_curve(model, X_train, y_train)
plot_roc(y_test, y_probas, labels)
plot_precision_recall(y_test, y_probas, labels)
plot_feature_importances(model)

# [optional] finish the wandb run, necessary in notebooks
run.finish()" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<ul dir="auto">
<li _msttexthash="18554107" _msthash="384">运行示例 <a href="https://wandb.me/scikit-colab?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">Google Colab Notebook</a>。</li>
<li _msttexthash="242944936" _msthash="385">阅读<a href="https://docs.wandb.ai/guides/integrations/scikit?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=integrations" rel="nofollow" _istranslated="1">开发人员指南</a>，了解有关如何将 Scikit-Learn 与 W&amp;B 集成的技术详细信息。</li>
</ul>
</details>
<p dir="auto">&nbsp;</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="20167043" _msthash="386">W&amp;B 托管选项</h1><a id="user-content-wb-hosting-options" class="anchor" aria-label="永久链接：W&amp;B 托管选项" href="#wb-hosting-options" _mstaria-label="884195" _msthash="387"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="708580197" _msthash="388">Weights &amp; Biases可以在云中使用，也可以安装在您的私有基础设施上。通过以下三种方式之一在生产环境中设置W&amp;B服务器：</p>
<ol dir="auto">
<li _msttexthash="367878368" _msthash="389"><a href="https://docs.wandb.ai/guides/hosting/hosting-options/self-managed#on-prem-private-cloud?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=hosting" rel="nofollow" _istranslated="1">生产云</a>：使用 W&amp;B 提供的 terraform 脚本，只需几个步骤即可在私有云上设置生产部署。</li>
<li _msttexthash="317635955" _msthash="390"><a href="https://docs.wandb.ai/guides/hosting/hosting-options/wb-managed#dedicated-cloud?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=hosting" rel="nofollow" _istranslated="1">专用云</a>：在您选择的云区域中，在 W&amp;B 的单租户基础设施上进行托管的专用部署。</li>
<li><font _mstmutation="1" _msttexthash="858068003" _msthash="391"><a href="https://docs.wandb.ai/guides/hosting/how-to-guides/bare-metal?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=hosting" rel="nofollow" _mstmutation="1" _istranslated="1">本地/裸机</a>：W&amp;B支持在您的本地数据中心的大多数裸机服务器上设置生产服务器。通过跑步快速开始，轻松开始在您的本地基础设施上托管W&amp;B。</font><code>wandb server</code></li>
</ol>
<p dir="auto" _msttexthash="150934953" _msthash="392">有关更多信息，请参阅 W&amp;B 开发人员指南中的<a href="https://docs.wandb.ai/guides/hosting?utm_source=github&amp;utm_medium=code&amp;utm_campaign=wandb&amp;utm_content=hosting" rel="nofollow" _istranslated="1">托管文档</a>。</p>

<p dir="auto">&nbsp;</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="20154082" _msthash="393">Python 版本支持</h1><a id="user-content-python-version-support" class="anchor" aria-label="永久链接：Python 版本支持" href="#python-version-support" _mstaria-label="891410" _msthash="394"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="857095928" _msthash="395">我们承诺在 Python 软件基金会定义的正式生命周期终止 （EOL） 日期后<em _istranslated="1">至少</em>六个月内支持我们所需的最低 Python 版本。您可以<a href="https://devguide.python.org/versions/" rel="nofollow" _istranslated="1">在此处</a>找到 Python EOL 日期列表。</p>
<p dir="auto" _msttexthash="301956304" _msthash="396">当我们停止对 Python 版本的支持时，我们将递增库的次要版本号以反映此更改。</p>
<p dir="auto">&nbsp;</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="11535771" _msthash="397">贡献准则</h1><a id="user-content-contribution-guidelines" class="anchor" aria-label="永久链接：贡献指南" href="#contribution-guidelines" _mstaria-label="988052" _msthash="398"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="1340181102" _msthash="399">Weights &amp; Biases ❤️开源，我们欢迎社区的贡献！有关开发工作流程和 wandb 库内部的更多信息，请参阅<a href="https://github.com/wandb/wandb/blob/main/CONTRIBUTING.md" _istranslated="1">贡献指南</a>。有关 wandb 错误和功能请求，请访问 <a href="https://github.com/wandb/wandb/issues" _istranslated="1">GitHub 问题</a>或联系 <a href="mailto:support@wandb.com" _istranslated="1">support@wandb.com</a>。</p>
<p dir="auto">&nbsp;</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="7101289" _msthash="400">W&amp;B 社区</h1><a id="user-content-wb-community" class="anchor" aria-label="永久链接：W&amp;B 社区" href="#wb-community" _mstaria-label="648479" _msthash="401"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="592882264" _msthash="402">成为不断增长的W&amp;B社区的一部分，并在我们的<a href="https://wandb.me/discord" rel="nofollow" _istranslated="1">Discord</a>中与W&amp;B团队互动。通过<a href="https://wandb.ai/fully-connected" rel="nofollow" _istranslated="1">W&amp;B Fully Connected</a>与最新的ML更新和教程保持联系。</p>
<p dir="auto">&nbsp;</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="9675445" _msthash="403">许可证</h1><a id="user-content-license" class="anchor" aria-label="永久链接：许可证" href="#license" _mstaria-label="331903" _msthash="404"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a href="https://github.com/wandb/wandb/blob/main/LICENSE" _msttexthash="13328120" _msthash="405">MIT 许可证</a></p>
</article></div>
